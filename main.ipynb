{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Networks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5913b1d511ccdaa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating image classifier using neural networks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49c447cc08fb96dd"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:11.786765400Z",
     "start_time": "2024-10-01T16:42:04.425888800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the Fashion MNIST dataset from Keras"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1a49fc9c2e1b075"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.013442200Z",
     "start_time": "2024-10-01T16:42:11.786765400Z"
    }
   },
   "id": "addeefdfa93431c2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.030713700Z",
     "start_time": "2024-10-01T16:42:12.014439700Z"
    }
   },
   "id": "96b19bed673244d9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('uint8')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.031712300Z",
     "start_time": "2024-10-01T16:42:12.021700100Z"
    }
   },
   "id": "82b89ab79fc88b0f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.092553900Z",
     "start_time": "2024-10-01T16:42:12.025713400Z"
    }
   },
   "id": "3e76c72a786b235b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.092553900Z",
     "start_time": "2024-10-01T16:42:12.087013400Z"
    }
   },
   "id": "f65cde41318dbf60",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the model using the Sequential API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4687f0e57901b5d2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.205807600Z",
     "start_time": "2024-10-01T16:42:12.092553900Z"
    }
   },
   "id": "49d8be41dc95bf66",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m784\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)            │       \u001B[38;5;34m235,500\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │        \u001B[38;5;34m30,100\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m1,010\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m266,610\u001B[0m (1.02 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m266,610\u001B[0m (1.02 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.215391300Z",
     "start_time": "2024-10-01T16:42:12.199808100Z"
    }
   },
   "id": "fdbc12f0b2c92c8d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[<Flatten name=flatten, built=True>,\n <Dense name=dense, built=True>,\n <Dense name=dense_1, built=True>,\n <Dense name=dense_2, built=True>]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.220023600Z",
     "start_time": "2024-10-01T16:42:12.214391300Z"
    }
   },
   "id": "d07836d112c002b4",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'dense'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.265893900Z",
     "start_time": "2024-10-01T16:42:12.219023500Z"
    }
   },
   "id": "5bfb362440107328",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.267893800Z",
     "start_time": "2024-10-01T16:42:12.224590400Z"
    }
   },
   "id": "756304cb08eb2bb4",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.267893800Z",
     "start_time": "2024-10-01T16:42:12.229507400Z"
    }
   },
   "id": "c852890192fda587",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.02132411,  0.03657039, -0.05774292, ..., -0.00324395,\n        -0.05883848,  0.02580044],\n       [ 0.02563734, -0.06724993,  0.02516256, ..., -0.03287431,\n        -0.05486884,  0.07008216],\n       [ 0.02061331, -0.00577582,  0.05602574, ...,  0.01395348,\n        -0.03912337, -0.0619952 ],\n       ...,\n       [ 0.01813702,  0.06608863, -0.0316261 , ..., -0.06403399,\n        -0.05405948, -0.05857508],\n       [-0.02434084,  0.03288862, -0.03324289, ...,  0.01834885,\n         0.0509599 , -0.0446647 ],\n       [ 0.06797203,  0.04383882,  0.07223085, ..., -0.06198711,\n         0.04436617, -0.06973015]], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.280957500Z",
     "start_time": "2024-10-01T16:42:12.241867800Z"
    }
   },
   "id": "5de6ab9e42577428",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(784, 300)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.323764Z",
     "start_time": "2024-10-01T16:42:12.246319900Z"
    }
   },
   "id": "1597e654105cd615",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.324760800Z",
     "start_time": "2024-10-01T16:42:12.252397100Z"
    }
   },
   "id": "6e04c8c735582194",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(300,)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.325759400Z",
     "start_time": "2024-10-01T16:42:12.258411100Z"
    }
   },
   "id": "70dfaeec4cabd25b",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compile the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1765c1d5aab0f86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:12.342277700Z",
     "start_time": "2024-10-01T16:42:12.262896Z"
    }
   },
   "id": "e944794c0e0ed498",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9252055fc5081f96"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 860us/step - accuracy: 0.6897 - loss: 0.9839 - val_accuracy: 0.8286 - val_loss: 0.5058\n",
      "Epoch 2/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 801us/step - accuracy: 0.8251 - loss: 0.5049 - val_accuracy: 0.8462 - val_loss: 0.4485\n",
      "Epoch 3/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 781us/step - accuracy: 0.8449 - loss: 0.4461 - val_accuracy: 0.8512 - val_loss: 0.4281\n",
      "Epoch 4/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 780us/step - accuracy: 0.8526 - loss: 0.4217 - val_accuracy: 0.8658 - val_loss: 0.3923\n",
      "Epoch 5/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 780us/step - accuracy: 0.8645 - loss: 0.3939 - val_accuracy: 0.8726 - val_loss: 0.3760\n",
      "Epoch 6/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 753us/step - accuracy: 0.8674 - loss: 0.3759 - val_accuracy: 0.8622 - val_loss: 0.3875\n",
      "Epoch 7/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 773us/step - accuracy: 0.8750 - loss: 0.3591 - val_accuracy: 0.8746 - val_loss: 0.3687\n",
      "Epoch 8/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 781us/step - accuracy: 0.8753 - loss: 0.3557 - val_accuracy: 0.8668 - val_loss: 0.3724\n",
      "Epoch 9/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 808us/step - accuracy: 0.8797 - loss: 0.3407 - val_accuracy: 0.8802 - val_loss: 0.3417\n",
      "Epoch 10/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 805us/step - accuracy: 0.8832 - loss: 0.3292 - val_accuracy: 0.8766 - val_loss: 0.3511\n",
      "Epoch 11/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 812us/step - accuracy: 0.8866 - loss: 0.3221 - val_accuracy: 0.8860 - val_loss: 0.3319\n",
      "Epoch 12/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 789us/step - accuracy: 0.8891 - loss: 0.3155 - val_accuracy: 0.8866 - val_loss: 0.3283\n",
      "Epoch 13/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 774us/step - accuracy: 0.8876 - loss: 0.3088 - val_accuracy: 0.8864 - val_loss: 0.3211\n",
      "Epoch 14/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 783us/step - accuracy: 0.8890 - loss: 0.3060 - val_accuracy: 0.8816 - val_loss: 0.3273\n",
      "Epoch 15/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 789us/step - accuracy: 0.8934 - loss: 0.2978 - val_accuracy: 0.8744 - val_loss: 0.3617\n",
      "Epoch 16/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 791us/step - accuracy: 0.8936 - loss: 0.2917 - val_accuracy: 0.8860 - val_loss: 0.3153\n",
      "Epoch 17/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 755us/step - accuracy: 0.8978 - loss: 0.2843 - val_accuracy: 0.8838 - val_loss: 0.3212\n",
      "Epoch 18/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 768us/step - accuracy: 0.9004 - loss: 0.2754 - val_accuracy: 0.8918 - val_loss: 0.3052\n",
      "Epoch 19/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 772us/step - accuracy: 0.9030 - loss: 0.2728 - val_accuracy: 0.8874 - val_loss: 0.3112\n",
      "Epoch 20/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 778us/step - accuracy: 0.9063 - loss: 0.2632 - val_accuracy: 0.8808 - val_loss: 0.3208\n",
      "Epoch 21/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 779us/step - accuracy: 0.9060 - loss: 0.2595 - val_accuracy: 0.8904 - val_loss: 0.3047\n",
      "Epoch 22/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 763us/step - accuracy: 0.9065 - loss: 0.2561 - val_accuracy: 0.8878 - val_loss: 0.3215\n",
      "Epoch 23/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 782us/step - accuracy: 0.9100 - loss: 0.2506 - val_accuracy: 0.8940 - val_loss: 0.3005\n",
      "Epoch 24/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 741us/step - accuracy: 0.9108 - loss: 0.2482 - val_accuracy: 0.8848 - val_loss: 0.3053\n",
      "Epoch 25/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 732us/step - accuracy: 0.9140 - loss: 0.2445 - val_accuracy: 0.8874 - val_loss: 0.3093\n",
      "Epoch 26/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 748us/step - accuracy: 0.9154 - loss: 0.2370 - val_accuracy: 0.8924 - val_loss: 0.3022\n",
      "Epoch 27/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 768us/step - accuracy: 0.9158 - loss: 0.2365 - val_accuracy: 0.8968 - val_loss: 0.2945\n",
      "Epoch 28/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 767us/step - accuracy: 0.9165 - loss: 0.2325 - val_accuracy: 0.8954 - val_loss: 0.2897\n",
      "Epoch 29/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 772us/step - accuracy: 0.9191 - loss: 0.2241 - val_accuracy: 0.8886 - val_loss: 0.3051\n",
      "Epoch 30/30\n",
      "\u001B[1m1719/1719\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 775us/step - accuracy: 0.9195 - loss: 0.2259 - val_accuracy: 0.8964 - val_loss: 0.2949\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:53.411060300Z",
     "start_time": "2024-10-01T16:42:12.273957400Z"
    }
   },
   "id": "b97277edaee932e6",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:54.109757700Z",
     "start_time": "2024-10-01T16:42:53.412060300Z"
    }
   },
   "id": "ea7e88723363ef19",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - accuracy: 0.8482 - loss: 63.5494\n"
     ]
    },
    {
     "data": {
      "text/plain": "[65.15414428710938, 0.8449000120162964]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:54.413280800Z",
     "start_time": "2024-10-01T16:42:54.110757900Z"
    }
   },
   "id": "32267903b2faa438",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Make predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6587a03ecf33b24a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:54.477835Z",
     "start_time": "2024-10-01T16:42:54.413280800Z"
    }
   },
   "id": "9180fdcf1990736c",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predict_classes no longer available in TensorFlow >= 2.6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba406ec2dc66bf1d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_classes\u001B[49m(X_new)\n\u001B[0;32m      2\u001B[0m y_pred\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:42:55.080046700Z",
     "start_time": "2024-10-01T16:42:54.472835300Z"
    }
   },
   "id": "78785aab4a8b7161",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a Regression MLP Using the Sequential API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c6d13a8ccd5c761"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:02.344669600Z",
     "start_time": "2024-10-01T16:45:00.322320700Z"
    }
   },
   "id": "e7970a5515f30414",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(8,)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:04.342313500Z",
     "start_time": "2024-10-01T16:45:04.333152400Z"
    }
   },
   "id": "18ab9ccda5c3d206",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m  1/363\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m40s\u001B[0m 113ms/step - loss: 4.0112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 808us/step - loss: 1.5785 - val_loss: 0.6360\n",
      "Epoch 2/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.6110 - val_loss: 0.5222\n",
      "Epoch 3/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 570us/step - loss: 0.4900 - val_loss: 0.4919\n",
      "Epoch 4/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.4696 - val_loss: 0.4768\n",
      "Epoch 5/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.4619 - val_loss: 0.4697\n",
      "Epoch 6/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.4498 - val_loss: 0.4547\n",
      "Epoch 7/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.4210 - val_loss: 0.4489\n",
      "Epoch 8/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 553us/step - loss: 0.4376 - val_loss: 0.4421\n",
      "Epoch 9/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 535us/step - loss: 0.4298 - val_loss: 0.4307\n",
      "Epoch 10/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.4271 - val_loss: 0.4307\n",
      "Epoch 11/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.4119 - val_loss: 0.4297\n",
      "Epoch 12/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.4058 - val_loss: 0.4232\n",
      "Epoch 13/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 546us/step - loss: 0.4010 - val_loss: 0.4144\n",
      "Epoch 14/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.4064 - val_loss: 0.4133\n",
      "Epoch 15/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 539us/step - loss: 0.3926 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.3964 - val_loss: 0.4141\n",
      "Epoch 17/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 542us/step - loss: 0.3909 - val_loss: 0.4038\n",
      "Epoch 18/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.3969 - val_loss: 0.4013\n",
      "Epoch 19/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3922 - val_loss: 0.4019\n",
      "Epoch 20/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.3891 - val_loss: 0.3960\n",
      "\u001B[1m162/162\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 453us/step - loss: 0.3860\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:10.504769Z",
     "start_time": "2024-10-01T16:45:05.679908300Z"
    }
   },
   "id": "868c0dab38e39574",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building Complex Models Using the Functional API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51aeb55f0cb1784c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:10.520666300Z",
     "start_time": "2024-10-01T16:45:10.504769Z"
    }
   },
   "id": "76ef6a40ff8bb065",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 772us/step - loss: 1.4120 - val_loss: 0.6890\n",
      "Epoch 2/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.9962 - val_loss: 0.5028\n",
      "Epoch 3/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.4792 - val_loss: 0.4687\n",
      "Epoch 4/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4480 - val_loss: 0.4488\n",
      "Epoch 5/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.4409 - val_loss: 0.4374\n",
      "Epoch 6/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.7824 - val_loss: 0.4343\n",
      "Epoch 7/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.4169 - val_loss: 0.4194\n",
      "Epoch 8/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.4165 - val_loss: 0.4014\n",
      "Epoch 9/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.3720 - val_loss: 0.4542\n",
      "Epoch 10/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.4669 - val_loss: 1.1776\n",
      "Epoch 11/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4813 - val_loss: 0.4118\n",
      "Epoch 12/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.4122 - val_loss: 0.3906\n",
      "Epoch 13/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4061 - val_loss: 0.4651\n",
      "Epoch 14/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.3825 - val_loss: 0.3862\n",
      "Epoch 15/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3689 - val_loss: 0.3662\n",
      "Epoch 16/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.3417 - val_loss: 0.3620\n",
      "Epoch 17/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3504 - val_loss: 0.3601\n",
      "Epoch 18/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.3439 - val_loss: 0.3581\n",
      "Epoch 19/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3558 - val_loss: 0.3598\n",
      "Epoch 20/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3245 - val_loss: 0.3687\n",
      "\u001B[1m162/162\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 371us/step - loss: 0.3410\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:16.114548Z",
     "start_time": "2024-10-01T16:45:11.055305Z"
    }
   },
   "id": "2ccbefcbff916e30",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_5\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m270\u001B[0m │ input_layer_2[\u001B[38;5;34m0\u001B[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m930\u001B[0m │ dense_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m38\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ input_layer_2[\u001B[38;5;34m0\u001B[0m]… │\n│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ dense_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m39\u001B[0m │ concatenate[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,241\u001B[0m (4.85 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,241</span> (4.85 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,239\u001B[0m (4.84 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,239</span> (4.84 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m2\u001B[0m (12.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:16.128502600Z",
     "start_time": "2024-10-01T16:45:16.110547900Z"
    }
   },
   "id": "e2ad7a11fde1e2d2",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multiple inputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "611dc0c1eb9b20a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:16.148608400Z",
     "start_time": "2024-10-01T16:45:16.122500100Z"
    }
   },
   "id": "8a72b60dbe3b9745",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:16.150606700Z",
     "start_time": "2024-10-01T16:45:16.143219Z"
    }
   },
   "id": "56f213a9f367ef49",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 827us/step - loss: 1.7466 - val_loss: 0.5724\n",
      "Epoch 2/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.6114 - val_loss: 0.5123\n",
      "Epoch 3/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.6059 - val_loss: 0.5062\n",
      "Epoch 4/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5555 - val_loss: 0.4966\n",
      "Epoch 5/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5026 - val_loss: 0.5047\n",
      "Epoch 6/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.4587 - val_loss: 0.4524\n",
      "Epoch 7/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.4579 - val_loss: 0.4464\n",
      "Epoch 8/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.4841 - val_loss: 0.4352\n",
      "Epoch 9/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.4334 - val_loss: 0.4232\n",
      "Epoch 10/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3896 - val_loss: 0.4149\n",
      "Epoch 11/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.4246 - val_loss: 0.4102\n",
      "Epoch 12/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3880 - val_loss: 0.4145\n",
      "Epoch 13/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.3907 - val_loss: 0.4011\n",
      "Epoch 14/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3941 - val_loss: 0.3891\n",
      "Epoch 15/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3825 - val_loss: 0.3943\n",
      "Epoch 16/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3889 - val_loss: 0.3841\n",
      "Epoch 17/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 0.3685 - val_loss: 0.3805\n",
      "Epoch 18/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3424 - val_loss: 0.3788\n",
      "Epoch 19/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3581 - val_loss: 0.3735\n",
      "Epoch 20/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.3492 - val_loss: 0.3655\n",
      "\u001B[1m162/162\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 416us/step - loss: 0.3373\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:22.002799500Z",
     "start_time": "2024-10-01T16:45:16.837875200Z"
    }
   },
   "id": "dc0efd8fe591eda5",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_6\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ deep_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m210\u001B[0m │ deep_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ wide_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m930\u001B[0m │ dense_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m35\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ wide_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ dense_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output (\u001B[38;5;33mDense\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m36\u001B[0m │ concatenate_1[\u001B[38;5;34m0\u001B[0m]… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ deep_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ deep_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ wide_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ wide_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,178\u001B[0m (4.61 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,178</span> (4.61 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,176\u001B[0m (4.59 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> (4.59 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m2\u001B[0m (12.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:22.016149300Z",
     "start_time": "2024-10-01T16:45:22.000799500Z"
    }
   },
   "id": "4232f1ac7561f68f",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict((X_new_A, X_new_B))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:22.093566600Z",
     "start_time": "2024-10-01T16:45:22.014148600Z"
    }
   },
   "id": "f05a02eaa70a5bcb",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.2811526],\n       [2.524687 ],\n       [1.935304 ]], dtype=float32)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:45:22.094567600Z",
     "start_time": "2024-10-01T16:45:22.084555900Z"
    }
   },
   "id": "3d0c9b6da73fced1",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Multiple outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f58c60c2cf9c9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:48:07.380047300Z",
     "start_time": "2024-10-01T16:48:07.356060700Z"
    }
   },
   "id": "b5828bdd625d4c37",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:48:17.392194500Z",
     "start_time": "2024-10-01T16:48:17.385799400Z"
    }
   },
   "id": "90c2b8064b69c0be",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 916us/step - aux_output_loss: 0.2737 - loss: 1.8421 - main_output_loss: 1.5684 - val_aux_output_loss: 0.1109 - val_loss: 0.6079 - val_main_output_loss: 0.4969\n",
      "Epoch 2/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - aux_output_loss: 0.1047 - loss: 0.5926 - main_output_loss: 0.4879 - val_aux_output_loss: 0.0907 - val_loss: 0.5457 - val_main_output_loss: 0.4549\n",
      "Epoch 3/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - aux_output_loss: 0.0852 - loss: 0.5327 - main_output_loss: 0.4475 - val_aux_output_loss: 0.0809 - val_loss: 0.5109 - val_main_output_loss: 0.4300\n",
      "Epoch 4/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - aux_output_loss: 0.0801 - loss: 0.5135 - main_output_loss: 0.4334 - val_aux_output_loss: 0.0743 - val_loss: 0.4979 - val_main_output_loss: 0.4236\n",
      "Epoch 5/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - aux_output_loss: 0.0714 - loss: 0.4759 - main_output_loss: 0.4044 - val_aux_output_loss: 0.0692 - val_loss: 0.4953 - val_main_output_loss: 0.4261\n",
      "Epoch 6/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - aux_output_loss: 0.0675 - loss: 0.4856 - main_output_loss: 0.4181 - val_aux_output_loss: 0.0660 - val_loss: 0.4724 - val_main_output_loss: 0.4063\n",
      "Epoch 7/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - aux_output_loss: 0.0665 - loss: 0.4765 - main_output_loss: 0.4099 - val_aux_output_loss: 0.0646 - val_loss: 0.4648 - val_main_output_loss: 0.4001\n",
      "Epoch 8/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - aux_output_loss: 0.0632 - loss: 0.4846 - main_output_loss: 0.4213 - val_aux_output_loss: 0.0617 - val_loss: 0.4526 - val_main_output_loss: 0.3909\n",
      "Epoch 9/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - aux_output_loss: 0.0613 - loss: 0.4617 - main_output_loss: 0.4004 - val_aux_output_loss: 0.0603 - val_loss: 0.4445 - val_main_output_loss: 0.3841\n",
      "Epoch 10/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - aux_output_loss: 0.0594 - loss: 0.4419 - main_output_loss: 0.3825 - val_aux_output_loss: 0.0587 - val_loss: 0.5210 - val_main_output_loss: 0.4622\n",
      "Epoch 11/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - aux_output_loss: 0.0576 - loss: 0.4621 - main_output_loss: 0.4045 - val_aux_output_loss: 0.0566 - val_loss: 0.4339 - val_main_output_loss: 0.3772\n",
      "Epoch 12/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - aux_output_loss: 0.0560 - loss: 0.4343 - main_output_loss: 0.3783 - val_aux_output_loss: 0.0558 - val_loss: 0.4208 - val_main_output_loss: 0.3650\n",
      "Epoch 13/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - aux_output_loss: 0.0573 - loss: 0.4967 - main_output_loss: 0.4394 - val_aux_output_loss: 0.0647 - val_loss: 0.4647 - val_main_output_loss: 0.3999\n",
      "Epoch 14/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - aux_output_loss: 0.0613 - loss: 0.4716 - main_output_loss: 0.4103 - val_aux_output_loss: 0.0550 - val_loss: 0.4369 - val_main_output_loss: 0.3818\n",
      "Epoch 15/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - aux_output_loss: 0.0551 - loss: 0.8611 - main_output_loss: 0.8060 - val_aux_output_loss: 0.0545 - val_loss: 0.4186 - val_main_output_loss: 0.3640\n",
      "Epoch 16/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - aux_output_loss: 0.0610 - loss: 0.4118 - main_output_loss: 0.3508 - val_aux_output_loss: 0.0530 - val_loss: 0.4023 - val_main_output_loss: 0.3493\n",
      "Epoch 17/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - aux_output_loss: 0.0536 - loss: 0.3909 - main_output_loss: 0.3374 - val_aux_output_loss: 0.0514 - val_loss: 0.3953 - val_main_output_loss: 0.3439\n",
      "Epoch 18/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - aux_output_loss: 0.0501 - loss: 0.3775 - main_output_loss: 0.3274 - val_aux_output_loss: 0.0513 - val_loss: 0.3939 - val_main_output_loss: 0.3425\n",
      "Epoch 19/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - aux_output_loss: 0.0499 - loss: 0.3831 - main_output_loss: 0.3332 - val_aux_output_loss: 0.0508 - val_loss: 0.4073 - val_main_output_loss: 0.3564\n",
      "Epoch 20/20\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - aux_output_loss: 0.0485 - loss: 0.3664 - main_output_loss: 0.3179 - val_aux_output_loss: 0.0525 - val_loss: 0.4116 - val_main_output_loss: 0.3590\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:49:35.757607300Z",
     "start_time": "2024-10-01T16:49:30.064969500Z"
    }
   },
   "id": "bc3eb5deb6c09a3b",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m162/162\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 443us/step - aux_output_loss: 0.0506 - loss: 0.3734 - main_output_loss: 0.3228\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:49:46.603483300Z",
     "start_time": "2024-10-01T16:49:46.487433Z"
    }
   },
   "id": "f361ec0eca6bdcea",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(0.376895546913147, 0.3263353705406189, 0.05060337111353874)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:50:10.236956600Z",
     "start_time": "2024-10-01T16:50:10.230956700Z"
    }
   },
   "id": "9266a947996e6aca",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:49:59.714868100Z",
     "start_time": "2024-10-01T16:49:59.656926800Z"
    }
   },
   "id": "36eb43f532c2585e",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[1.3059382],\n        [2.6325188],\n        [2.1316214]], dtype=float32),\n array([[1.0792636],\n        [2.4484568],\n        [2.0008779]], dtype=float32))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:50:16.791192300Z",
     "start_time": "2024-10-01T16:50:16.784811300Z"
    }
   },
   "id": "2cd67b64d9c912c0",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_7\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ deep_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m210\u001B[0m │ deep_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ wide_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m)        │        \u001B[38;5;34m930\u001B[0m │ dense_10[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m35\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ wide_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ dense_11[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ main_output (\u001B[38;5;33mDense\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m36\u001B[0m │ concatenate_2[\u001B[38;5;34m0\u001B[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ aux_output (\u001B[38;5;33mDense\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m31\u001B[0m │ dense_11[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ deep_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │ deep_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ wide_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ wide_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ main_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ aux_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,209\u001B[0m (4.73 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,209</span> (4.73 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,207\u001B[0m (4.71 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,207</span> (4.71 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m2\u001B[0m (12.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:50:24.113424300Z",
     "start_time": "2024-10-01T16:50:24.098378900Z"
    }
   },
   "id": "1174c70ee029d03b",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating dynamic models using the Subclassing API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d886c11faacda3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:54:30.088416100Z",
     "start_time": "2024-10-01T16:54:30.083146300Z"
    }
   },
   "id": "afd359e92bbc0722",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T16:54:34.421422800Z",
     "start_time": "2024-10-01T16:54:34.417906200Z"
    }
   },
   "id": "69e13d1484ac5ee2",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving and restoring a model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aef3a102cc33d058"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - loss: 3.3588 - val_loss: 1.1470\n",
      "Epoch 2/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 574us/step - loss: 1.0663 - val_loss: 0.8015\n",
      "Epoch 3/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.7481 - val_loss: 0.6815\n",
      "Epoch 4/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.6708 - val_loss: 0.6346\n",
      "Epoch 5/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.6229 - val_loss: 0.6069\n",
      "Epoch 6/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.5916 - val_loss: 0.5853\n",
      "Epoch 7/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5651 - val_loss: 0.5683\n",
      "Epoch 8/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.5527 - val_loss: 0.5535\n",
      "Epoch 9/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.5411 - val_loss: 0.5407\n",
      "Epoch 10/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5305 - val_loss: 0.5297\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=(8,)),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.001))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:04:04.011653600Z",
     "start_time": "2024-10-01T17:04:01.460814Z"
    }
   },
   "id": "3ce43e4889939e10",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:04:09.117254300Z",
     "start_time": "2024-10-01T17:04:09.103915600Z"
    }
   },
   "id": "2ed25455f5e0890c",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:04:10.149440800Z",
     "start_time": "2024-10-01T17:04:10.114822200Z"
    }
   },
   "id": "93591d27a0f8f03",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem with loading model when compiling with learning_rate=1e-3. You can load and then compile or compile with learning_rate=0.001 instead."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8654181ddeea744"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.keras\", compile=False)\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:03:32.691559900Z",
     "start_time": "2024-10-01T17:03:32.664049Z"
    }
   },
   "id": "c0a44e2d9e25370",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c97c3caf6f79c0e7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 814us/step - loss: 0.5211 - val_loss: 0.5195\n",
      "Epoch 2/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5199 - val_loss: 0.5105\n",
      "Epoch 3/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.4871 - val_loss: 0.5024\n",
      "Epoch 4/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4804 - val_loss: 0.4951\n",
      "Epoch 5/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.4858 - val_loss: 0.4885\n",
      "Epoch 6/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4696 - val_loss: 0.4831\n",
      "Epoch 7/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.4384 - val_loss: 0.4772\n",
      "Epoch 8/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 780us/step - loss: 0.4445 - val_loss: 0.4726\n",
      "Epoch 9/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4439 - val_loss: 0.4684\n",
      "Epoch 10/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4415 - val_loss: 0.4639\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.keras\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:24:39.522738400Z",
     "start_time": "2024-10-01T17:24:36.858572200Z"
    }
   },
   "id": "48f6f6d0d89fa85c",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Early stopping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c89707e234864b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.4632 - val_loss: 0.4602\n",
      "Epoch 2/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4596 - val_loss: 0.4568\n",
      "Epoch 3/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.4442 - val_loss: 0.4539\n",
      "Epoch 4/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.4415 - val_loss: 0.4511\n",
      "Epoch 5/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.4371 - val_loss: 0.4485\n",
      "Epoch 6/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.4273 - val_loss: 0.4461\n",
      "Epoch 7/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4505 - val_loss: 0.4435\n",
      "Epoch 8/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.4228 - val_loss: 0.4418\n",
      "Epoch 9/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.4213 - val_loss: 0.4398\n",
      "Epoch 10/10\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.4311 - val_loss: 0.4381\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.keras\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.keras\") #going back to best model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:26:53.393938400Z",
     "start_time": "2024-10-01T17:26:50.933198500Z"
    }
   },
   "id": "7325747b303c08f4",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 802us/step - loss: 0.4165 - val_loss: 0.4361\n",
      "Epoch 2/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.4123 - val_loss: 0.4341\n",
      "Epoch 3/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 772us/step - loss: 0.4112 - val_loss: 0.4327\n",
      "Epoch 4/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.4129 - val_loss: 0.4318\n",
      "Epoch 5/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4104 - val_loss: 0.4295\n",
      "Epoch 6/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4261 - val_loss: 0.4284\n",
      "Epoch 7/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.4229 - val_loss: 0.4268\n",
      "Epoch 8/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.4207 - val_loss: 0.4255\n",
      "Epoch 9/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4076 - val_loss: 0.4246\n",
      "Epoch 10/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4005 - val_loss: 0.4230\n",
      "Epoch 11/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.4017 - val_loss: 0.4219\n",
      "Epoch 12/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.4018 - val_loss: 0.4207\n",
      "Epoch 13/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3978 - val_loss: 0.4194\n",
      "Epoch 14/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4071 - val_loss: 0.4182\n",
      "Epoch 15/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3919 - val_loss: 0.4173\n",
      "Epoch 16/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.3995 - val_loss: 0.4164\n",
      "Epoch 17/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.4040 - val_loss: 0.4149\n",
      "Epoch 18/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 0.3884 - val_loss: 0.4136\n",
      "Epoch 19/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3877 - val_loss: 0.4124\n",
      "Epoch 20/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.3833 - val_loss: 0.4113\n",
      "Epoch 21/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.3955 - val_loss: 0.4106\n",
      "Epoch 22/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.3817 - val_loss: 0.4096\n",
      "Epoch 23/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3875 - val_loss: 0.4083\n",
      "Epoch 24/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.3806 - val_loss: 0.4067\n",
      "Epoch 25/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.3944 - val_loss: 0.4059\n",
      "Epoch 26/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3794 - val_loss: 0.4056\n",
      "Epoch 27/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.3734 - val_loss: 0.4041\n",
      "Epoch 28/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.4070 - val_loss: 0.4027\n",
      "Epoch 29/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.3947 - val_loss: 0.4022\n",
      "Epoch 30/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.3730 - val_loss: 0.4022\n",
      "Epoch 31/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3886 - val_loss: 0.4010\n",
      "Epoch 32/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.3923 - val_loss: 0.4002\n",
      "Epoch 33/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.3779 - val_loss: 0.3981\n",
      "Epoch 34/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3613 - val_loss: 0.3976\n",
      "Epoch 35/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.3880 - val_loss: 0.3967\n",
      "Epoch 36/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.3884 - val_loss: 0.3960\n",
      "Epoch 37/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.3859 - val_loss: 0.3948\n",
      "Epoch 38/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.3787 - val_loss: 0.3946\n",
      "Epoch 39/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 0.3876 - val_loss: 0.3933\n",
      "Epoch 40/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.3758 - val_loss: 0.3927\n",
      "Epoch 41/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3780 - val_loss: 0.3918\n",
      "Epoch 42/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.3717 - val_loss: 0.3911\n",
      "Epoch 43/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.3781 - val_loss: 0.3905\n",
      "Epoch 44/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.3800 - val_loss: 0.3895\n",
      "Epoch 45/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.3692 - val_loss: 0.3885\n",
      "Epoch 46/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3913 - val_loss: 0.3877\n",
      "Epoch 47/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3622 - val_loss: 0.3872\n",
      "Epoch 48/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3783 - val_loss: 0.3871\n",
      "Epoch 49/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3651 - val_loss: 0.3866\n",
      "Epoch 50/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3665 - val_loss: 0.3851\n",
      "Epoch 51/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3615 - val_loss: 0.3839\n",
      "Epoch 52/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3639 - val_loss: 0.3830\n",
      "Epoch 53/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.3718 - val_loss: 0.3825\n",
      "Epoch 54/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3700 - val_loss: 0.3820\n",
      "Epoch 55/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.3547 - val_loss: 0.3810\n",
      "Epoch 56/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3746 - val_loss: 0.3804\n",
      "Epoch 57/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3670 - val_loss: 0.3797\n",
      "Epoch 58/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558us/step - loss: 0.3439 - val_loss: 0.3807\n",
      "Epoch 59/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.3602 - val_loss: 0.3787\n",
      "Epoch 60/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3683 - val_loss: 0.3776\n",
      "Epoch 61/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.3583 - val_loss: 0.3774\n",
      "Epoch 62/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3465 - val_loss: 0.3768\n",
      "Epoch 63/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.3496 - val_loss: 0.3763\n",
      "Epoch 64/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.3807 - val_loss: 0.3754\n",
      "Epoch 65/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 0.3595 - val_loss: 0.3757\n",
      "Epoch 66/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3451 - val_loss: 0.3736\n",
      "Epoch 67/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.3568 - val_loss: 0.3728\n",
      "Epoch 68/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.3480 - val_loss: 0.3724\n",
      "Epoch 69/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3631 - val_loss: 0.3719\n",
      "Epoch 70/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3471 - val_loss: 0.3708\n",
      "Epoch 71/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 557us/step - loss: 0.3448 - val_loss: 0.3717\n",
      "Epoch 72/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.3463 - val_loss: 0.3704\n",
      "Epoch 73/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.3589 - val_loss: 0.3693\n",
      "Epoch 74/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3451 - val_loss: 0.3692\n",
      "Epoch 75/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.3480 - val_loss: 0.3680\n",
      "Epoch 76/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.3419 - val_loss: 0.3673\n",
      "Epoch 77/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.3385 - val_loss: 0.3668\n",
      "Epoch 78/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3491 - val_loss: 0.3662\n",
      "Epoch 79/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3592 - val_loss: 0.3658\n",
      "Epoch 80/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 561us/step - loss: 0.3414 - val_loss: 0.3659\n",
      "Epoch 81/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.3634 - val_loss: 0.3644\n",
      "Epoch 82/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 555us/step - loss: 0.3447 - val_loss: 0.3659\n",
      "Epoch 83/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.3392 - val_loss: 0.3631\n",
      "Epoch 84/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.3440 - val_loss: 0.3633\n",
      "Epoch 85/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.3523 - val_loss: 0.3634\n",
      "Epoch 86/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.3330 - val_loss: 0.3621\n",
      "Epoch 87/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.3483 - val_loss: 0.3613\n",
      "Epoch 88/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.3452 - val_loss: 0.3615\n",
      "Epoch 89/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.3448 - val_loss: 0.3605\n",
      "Epoch 90/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.3564 - val_loss: 0.3599\n",
      "Epoch 91/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3401 - val_loss: 0.3592\n",
      "Epoch 92/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3328 - val_loss: 0.3590\n",
      "Epoch 93/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.3371 - val_loss: 0.3581\n",
      "Epoch 94/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.3308 - val_loss: 0.3575\n",
      "Epoch 95/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.3469 - val_loss: 0.3574\n",
      "Epoch 96/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.3485 - val_loss: 0.3568\n",
      "Epoch 97/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3431 - val_loss: 0.3561\n",
      "Epoch 98/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3394 - val_loss: 0.3556\n",
      "Epoch 99/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3299 - val_loss: 0.3551\n",
      "Epoch 100/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3334 - val_loss: 0.3550\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:28:04.350314100Z",
     "start_time": "2024-10-01T17:27:40.635318200Z"
    }
   },
   "id": "e6bd45776608e6c8",
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Custom callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "473a7545ce49303"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:29:23.389001100Z",
     "start_time": "2024-10-01T17:29:23.379904600Z"
    }
   },
   "id": "d60d96d4163905f1",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using TensorBoard for Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff854036ede497a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:34:29.459364500Z",
     "start_time": "2024-10-01T17:34:29.451851200Z"
    }
   },
   "id": "3389f60decf16768",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=(8,)),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.001))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:35:50.227238800Z",
     "start_time": "2024-10-01T17:35:50.213250200Z"
    }
   },
   "id": "ebf5c1e8d28e956a",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 895us/step - loss: 2.4041 - val_loss: 0.9555\n",
      "Epoch 2/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.8959 - val_loss: 0.8074\n",
      "Epoch 3/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - loss: 0.7792 - val_loss: 0.7280\n",
      "Epoch 4/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.6841 - val_loss: 0.6830\n",
      "Epoch 5/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.6356 - val_loss: 0.6507\n",
      "Epoch 6/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - loss: 0.6406 - val_loss: 0.6259\n",
      "Epoch 7/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.6089 - val_loss: 0.6068\n",
      "Epoch 8/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step - loss: 0.5930 - val_loss: 0.5915\n",
      "Epoch 9/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.5689 - val_loss: 0.5764\n",
      "Epoch 10/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.5535 - val_loss: 0.5618\n",
      "Epoch 11/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.5590 - val_loss: 0.5560\n",
      "Epoch 12/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.5428 - val_loss: 0.5393\n",
      "Epoch 13/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.5688 - val_loss: 0.5321\n",
      "Epoch 14/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - loss: 0.5244 - val_loss: 0.5212\n",
      "Epoch 15/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - loss: 0.5206 - val_loss: 0.5147\n",
      "Epoch 16/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - loss: 0.5067 - val_loss: 0.5097\n",
      "Epoch 17/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.5168 - val_loss: 0.5011\n",
      "Epoch 18/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4845 - val_loss: 0.4952\n",
      "Epoch 19/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - loss: 0.4686 - val_loss: 0.4903\n",
      "Epoch 20/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4897 - val_loss: 0.4922\n",
      "Epoch 21/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.4588 - val_loss: 0.4819\n",
      "Epoch 22/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4778 - val_loss: 0.4784\n",
      "Epoch 23/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.4733 - val_loss: 0.4777\n",
      "Epoch 24/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4631 - val_loss: 0.4723\n",
      "Epoch 25/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.4706 - val_loss: 0.4699\n",
      "Epoch 26/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.4571 - val_loss: 0.4681\n",
      "Epoch 27/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4451 - val_loss: 0.4652\n",
      "Epoch 28/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.4615 - val_loss: 0.4634\n",
      "Epoch 29/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.4316 - val_loss: 0.4636\n",
      "Epoch 30/30\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.4381 - val_loss: 0.4590\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:36:13.593809800Z",
     "start_time": "2024-10-01T17:36:05.032129300Z"
    }
   },
   "id": "368055d3634ce02e",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b0b2e23b151258"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3)\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T17:43:41.846540400Z",
     "start_time": "2024-10-01T17:43:29.872936700Z"
    }
   },
   "id": "c62f639edd669dbb",
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6da52e46ba7147d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=(8,)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:06:58.413929400Z",
     "start_time": "2024-10-01T18:06:58.396878200Z"
    }
   },
   "id": "76a80c01d420503b",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "keras_reg = KerasRegressor(build_model, n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=(8,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:06:58.957644700Z",
     "start_time": "2024-10-01T18:06:58.944102800Z"
    }
   },
   "id": "8a3568cfca90738d",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 740us/step - loss: 2.3652 - val_loss: 0.7338\n",
      "Epoch 2/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 554us/step - loss: 0.7355 - val_loss: 0.6492\n",
      "Epoch 3/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.6053 - val_loss: 0.5955\n",
      "Epoch 4/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5754 - val_loss: 0.5586\n",
      "Epoch 5/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5341 - val_loss: 0.5326\n",
      "Epoch 6/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 543us/step - loss: 0.5253 - val_loss: 0.5145\n",
      "Epoch 7/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.5019 - val_loss: 0.5014\n",
      "Epoch 8/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.4665 - val_loss: 0.4927\n",
      "Epoch 9/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.4774 - val_loss: 0.4849\n",
      "Epoch 10/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558us/step - loss: 0.4804 - val_loss: 0.4791\n",
      "Epoch 11/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556us/step - loss: 0.4566 - val_loss: 0.4735\n",
      "Epoch 12/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - loss: 0.4641 - val_loss: 0.4701\n",
      "Epoch 13/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.4596 - val_loss: 0.4663\n",
      "Epoch 14/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.4553 - val_loss: 0.4640\n",
      "Epoch 15/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.4551 - val_loss: 0.4627\n",
      "Epoch 16/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.4472 - val_loss: 0.4575\n",
      "Epoch 17/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.4499 - val_loss: 0.4538\n",
      "Epoch 18/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.4768 - val_loss: 0.4528\n",
      "Epoch 19/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 0.4507 - val_loss: 0.4507\n",
      "Epoch 20/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.4405 - val_loss: 0.4488\n",
      "Epoch 21/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 541us/step - loss: 0.4744 - val_loss: 0.4468\n",
      "Epoch 22/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 553us/step - loss: 0.4286 - val_loss: 0.4439\n",
      "Epoch 23/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 541us/step - loss: 0.4532 - val_loss: 0.4422\n",
      "Epoch 24/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.4378 - val_loss: 0.4408\n",
      "Epoch 25/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.4347 - val_loss: 0.4396\n",
      "Epoch 26/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.4283 - val_loss: 0.4376\n",
      "Epoch 27/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.4535 - val_loss: 0.4368\n",
      "Epoch 28/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.4199 - val_loss: 0.4349\n",
      "Epoch 29/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 562us/step - loss: 0.4292 - val_loss: 0.4342\n",
      "Epoch 30/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 549us/step - loss: 0.4251 - val_loss: 0.4341\n",
      "Epoch 31/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.4379 - val_loss: 0.4319\n",
      "Epoch 32/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 561us/step - loss: 0.4330 - val_loss: 0.4285\n",
      "Epoch 33/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.4038 - val_loss: 0.4291\n",
      "Epoch 34/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551us/step - loss: 0.4114 - val_loss: 0.4281\n",
      "Epoch 35/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4383 - val_loss: 0.4280\n",
      "Epoch 36/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 565us/step - loss: 0.4011 - val_loss: 0.4258\n",
      "Epoch 37/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 567us/step - loss: 0.4189 - val_loss: 0.4224\n",
      "Epoch 38/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 557us/step - loss: 0.4034 - val_loss: 0.4228\n",
      "Epoch 39/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.4123 - val_loss: 0.4212\n",
      "Epoch 40/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 545us/step - loss: 0.3883 - val_loss: 0.4210\n",
      "Epoch 41/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.4256 - val_loss: 0.4190\n",
      "Epoch 42/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.4114 - val_loss: 0.4174\n",
      "Epoch 43/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551us/step - loss: 0.4069 - val_loss: 0.4171\n",
      "Epoch 44/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - loss: 0.4162 - val_loss: 0.4170\n",
      "Epoch 45/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 549us/step - loss: 0.4149 - val_loss: 0.4158\n",
      "Epoch 46/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 557us/step - loss: 0.4087 - val_loss: 0.4151\n",
      "Epoch 47/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3837 - val_loss: 0.4142\n",
      "Epoch 48/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558us/step - loss: 0.4183 - val_loss: 0.4153\n",
      "Epoch 49/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 541us/step - loss: 0.3924 - val_loss: 0.4175\n",
      "Epoch 50/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.4048 - val_loss: 0.4104\n",
      "Epoch 51/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.3970 - val_loss: 0.4102\n",
      "Epoch 52/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.4033 - val_loss: 0.4106\n",
      "Epoch 53/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 546us/step - loss: 0.3806 - val_loss: 0.4080\n",
      "Epoch 54/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 563us/step - loss: 0.4054 - val_loss: 0.4079\n",
      "Epoch 55/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.3980 - val_loss: 0.4061\n",
      "Epoch 56/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - loss: 0.3941 - val_loss: 0.4071\n",
      "Epoch 57/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.3887 - val_loss: 0.4041\n",
      "Epoch 58/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 535us/step - loss: 0.3820 - val_loss: 0.4098\n",
      "Epoch 59/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 536us/step - loss: 0.4041 - val_loss: 0.4026\n",
      "Epoch 60/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.3877 - val_loss: 0.4062\n",
      "Epoch 61/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.3768 - val_loss: 0.4001\n",
      "Epoch 62/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3856 - val_loss: 0.4006\n",
      "Epoch 63/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556us/step - loss: 0.3753 - val_loss: 0.4004\n",
      "Epoch 64/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 569us/step - loss: 0.3673 - val_loss: 0.3978\n",
      "Epoch 65/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.3801 - val_loss: 0.4030\n",
      "Epoch 66/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.4180 - val_loss: 0.3968\n",
      "Epoch 67/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 569us/step - loss: 0.3876 - val_loss: 0.3956\n",
      "Epoch 68/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 543us/step - loss: 0.3943 - val_loss: 0.3952\n",
      "Epoch 69/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 560us/step - loss: 0.3930 - val_loss: 0.3940\n",
      "Epoch 70/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.3856 - val_loss: 0.3932\n",
      "Epoch 71/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 560us/step - loss: 0.3767 - val_loss: 0.3923\n",
      "Epoch 72/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 561us/step - loss: 0.3694 - val_loss: 0.3916\n",
      "Epoch 73/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3730 - val_loss: 0.3904\n",
      "Epoch 74/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551us/step - loss: 0.3793 - val_loss: 0.4010\n",
      "Epoch 75/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 553us/step - loss: 0.3761 - val_loss: 0.3890\n",
      "Epoch 76/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - loss: 0.3724 - val_loss: 0.3875\n",
      "Epoch 77/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 549us/step - loss: 0.3649 - val_loss: 0.3873\n",
      "Epoch 78/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3865 - val_loss: 0.3869\n",
      "Epoch 79/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.3639 - val_loss: 0.3866\n",
      "Epoch 80/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 545us/step - loss: 0.3650 - val_loss: 0.3881\n",
      "Epoch 81/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.3668 - val_loss: 0.3857\n",
      "Epoch 82/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 544us/step - loss: 0.3871 - val_loss: 0.3898\n",
      "Epoch 83/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 549us/step - loss: 0.3755 - val_loss: 0.3832\n",
      "Epoch 84/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 541us/step - loss: 0.3645 - val_loss: 0.3934\n",
      "Epoch 85/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3695 - val_loss: 0.3828\n",
      "Epoch 86/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552us/step - loss: 0.3666 - val_loss: 0.3811\n",
      "Epoch 87/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 545us/step - loss: 0.3658 - val_loss: 0.3810\n",
      "Epoch 88/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.3823 - val_loss: 0.3848\n",
      "Epoch 89/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 542us/step - loss: 0.3716 - val_loss: 0.7059\n",
      "Epoch 90/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 540us/step - loss: 0.4078 - val_loss: 0.3789\n",
      "Epoch 91/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.3629 - val_loss: 0.3787\n",
      "Epoch 92/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 537us/step - loss: 0.3709 - val_loss: 0.3931\n",
      "Epoch 93/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 546us/step - loss: 0.3700 - val_loss: 0.3943\n",
      "Epoch 94/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - loss: 0.3853 - val_loss: 0.3765\n",
      "Epoch 95/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3665 - val_loss: 0.3752\n",
      "Epoch 96/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - loss: 0.3586 - val_loss: 0.3777\n",
      "Epoch 97/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551us/step - loss: 0.3702 - val_loss: 0.3749\n",
      "Epoch 98/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 538us/step - loss: 0.3696 - val_loss: 0.3738\n",
      "Epoch 99/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 549us/step - loss: 0.3670 - val_loss: 0.3739\n",
      "Epoch 100/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 550us/step - loss: 0.3574 - val_loss: 0.3730\n"
     ]
    },
    {
     "data": {
      "text/plain": "KerasRegressor(\n\tmodel=<function build_model at 0x0000021C8EEF0B80>\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tn_hidden=1\n\tn_neurons=30\n\tlearning_rate=0.003\n\tinput_shape=(8,)\n)",
      "text/html": "<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n\tmodel=&lt;function build_model at 0x0000021C8EEF0B80&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tn_hidden=1\n\tn_neurons=30\n\tlearning_rate=0.003\n\tinput_shape=(8,)\n)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n\tmodel=&lt;function build_model at 0x0000021C8EEF0B80&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tn_hidden=1\n\tn_neurons=30\n\tlearning_rate=0.003\n\tinput_shape=(8,)\n)</pre></div> </div></div></div></div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:07:21.649928300Z",
     "start_time": "2024-10-01T18:06:59.481205500Z"
    }
   },
   "id": "276aee68c2d6522a",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m162/162\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:07:22.016336100Z",
     "start_time": "2024-10-01T18:07:21.648928300Z"
    }
   },
   "id": "bd93f66cdda65b7c",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 992us/step - loss: 1.4293 - val_loss: 0.6937\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 3.5328 - val_loss: 0.5142\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4704 - val_loss: 0.4496\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.4018 - val_loss: 0.4053\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4077 - val_loss: 0.3911\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.3523 - val_loss: 0.3754\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3546 - val_loss: 0.3744\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3420 - val_loss: 0.3678\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3355 - val_loss: 0.3734\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.3526 - val_loss: 0.3606\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3234 - val_loss: 0.3641\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3387 - val_loss: 0.3517\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.3160 - val_loss: 0.3578\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.3373 - val_loss: 0.3681\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.3190 - val_loss: 0.3443\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3234 - val_loss: 0.3528\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - loss: 0.3097 - val_loss: 0.3534\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - loss: 0.3266 - val_loss: 0.3686\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3153 - val_loss: 0.3369\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 773us/step - loss: 0.3225 - val_loss: 0.3351\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3156 - val_loss: 0.3462\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3006 - val_loss: 0.3316\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.3068 - val_loss: 0.3372\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3043 - val_loss: 0.3319\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3092 - val_loss: 0.3309\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3049 - val_loss: 0.3282\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3070 - val_loss: 0.3306\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2810 - val_loss: 0.3228\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2916 - val_loss: 0.3290\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.2991 - val_loss: 0.3327\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.2919 - val_loss: 0.3277\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3042 - val_loss: 0.3338\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2883 - val_loss: 0.3195\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.2756 - val_loss: 0.3179\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.2973 - val_loss: 0.3177\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2928 - val_loss: 0.3206\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - loss: 0.2676 - val_loss: 0.3164\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.2912 - val_loss: 0.3190\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.2744 - val_loss: 0.3159\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2686 - val_loss: 0.3150\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.2730 - val_loss: 0.3304\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2834 - val_loss: 0.3229\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - loss: 0.2606 - val_loss: 0.3221\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2591 - val_loss: 0.3109\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2776 - val_loss: 0.3153\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2718 - val_loss: 0.3273\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.2651 - val_loss: 0.3079\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.2699 - val_loss: 0.3198\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - loss: 0.2645 - val_loss: 0.3140\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.2704 - val_loss: 0.3116\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2858 - val_loss: 0.3146\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2756 - val_loss: 0.3152\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.2717 - val_loss: 0.3079\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2765 - val_loss: 0.3098\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - loss: 0.2608 - val_loss: 0.3078\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.2561 - val_loss: 0.3097\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.2668 - val_loss: 0.3125\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - loss: 0.2716 - val_loss: 0.3301\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.2551 - val_loss: 0.3096\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - loss: 0.2565 - val_loss: 0.3149\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.2488 - val_loss: 0.3026\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.2491 - val_loss: 0.4031\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 797us/step - loss: 0.2707 - val_loss: 0.3043\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - loss: 0.2529 - val_loss: 0.3208\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.2572 - val_loss: 0.3075\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2593 - val_loss: 0.3002\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.2520 - val_loss: 0.3153\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.2649 - val_loss: 0.3042\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.2663 - val_loss: 0.3028\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.2590 - val_loss: 0.3034\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.2512 - val_loss: 0.3080\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.2543 - val_loss: 0.3026\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.2504 - val_loss: 0.2981\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 0.2439 - val_loss: 0.3091\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.2450 - val_loss: 0.2974\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.2564 - val_loss: 0.3041\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.2578 - val_loss: 0.2995\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - loss: 0.2302 - val_loss: 0.3007\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.2704 - val_loss: 0.3025\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.2436 - val_loss: 0.3005\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.2593 - val_loss: 0.3019\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.2618 - val_loss: 0.3083\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 0.2484 - val_loss: 0.2957\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 0.2533 - val_loss: 0.2928\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.2584 - val_loss: 0.2936\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.2534 - val_loss: 0.3062\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.2509 - val_loss: 0.2941\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.2611 - val_loss: 0.2976\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.2418 - val_loss: 0.2928\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.2537 - val_loss: 0.2958\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.2590 - val_loss: 0.3011\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.2446 - val_loss: 0.3061\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - loss: 0.2421 - val_loss: 0.2916\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.2347 - val_loss: 0.2907\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.2522 - val_loss: 0.2988\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.2483 - val_loss: 0.3115\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.2443 - val_loss: 0.3078\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.2513 - val_loss: 0.2964\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.2517 - val_loss: 0.2958\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.2379 - val_loss: 0.2909\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 936us/step - loss: 1.2027 - val_loss: 0.5685\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.5085 - val_loss: 0.5962\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.6394 - val_loss: 0.4889\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4940 - val_loss: 0.4535\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4263 - val_loss: 0.4379\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4354 - val_loss: 0.4299\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4046 - val_loss: 0.4196\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 0.3952 - val_loss: 0.4102\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.4003 - val_loss: 0.4221\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3823 - val_loss: 0.3994\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.3847 - val_loss: 0.3966\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3883 - val_loss: 0.3902\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.3907 - val_loss: 0.3836\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - loss: 0.3714 - val_loss: 0.3951\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - loss: 0.3594 - val_loss: 0.3797\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3952 - val_loss: 0.3783\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.3632 - val_loss: 0.3815\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 657us/step - loss: 0.3429 - val_loss: 0.3737\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3766 - val_loss: 0.3653\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3422 - val_loss: 0.3613\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3259 - val_loss: 0.3648\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3445 - val_loss: 0.3687\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3344 - val_loss: 0.3729\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.3379 - val_loss: 0.3671\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3431 - val_loss: 0.3600\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.3414 - val_loss: 0.3492\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3325 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3200 - val_loss: 0.3452\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3240 - val_loss: 0.3534\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3185 - val_loss: 0.3560\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.3177 - val_loss: 0.3467\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3200 - val_loss: 0.3407\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3154 - val_loss: 0.3401\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3104 - val_loss: 0.3377\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - loss: 0.3100 - val_loss: 0.3301\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.3149 - val_loss: 0.3400\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - loss: 0.3187 - val_loss: 0.3273\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.3215 - val_loss: 0.3433\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.2963 - val_loss: 0.3335\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.3024 - val_loss: 0.3267\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3003 - val_loss: 0.3213\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.2818 - val_loss: 0.3371\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3118 - val_loss: 0.3233\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.2915 - val_loss: 0.3239\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - loss: 0.3006 - val_loss: 0.3386\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3035 - val_loss: 0.3218\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.2967 - val_loss: 0.3228\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.2957 - val_loss: 0.3296\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - loss: 0.2914 - val_loss: 0.3164\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.2797 - val_loss: 0.3272\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2985 - val_loss: 0.3197\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.2941 - val_loss: 0.3132\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - loss: 0.2889 - val_loss: 0.3340\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.2940 - val_loss: 0.3233\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2789 - val_loss: 0.3147\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.2891 - val_loss: 0.3220\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.2853 - val_loss: 0.3215\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2857 - val_loss: 0.3133\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - loss: 0.2917 - val_loss: 0.3257\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - loss: 0.2930 - val_loss: 0.3258\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.2812 - val_loss: 0.3180\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.2833 - val_loss: 0.3413\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2901 - val_loss: 0.3151\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.2598 - val_loss: 0.3322\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.2774 - val_loss: 0.3080\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2786 - val_loss: 0.3102\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.2727 - val_loss: 0.3126\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.2746 - val_loss: 0.3109\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.3162 - val_loss: 0.3069\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.2746 - val_loss: 0.3066\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.2738 - val_loss: 0.3258\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2731 - val_loss: 0.3256\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.2716 - val_loss: 0.3424\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.2642 - val_loss: 0.3045\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2848 - val_loss: 0.3433\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.2990 - val_loss: 0.3390\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2798 - val_loss: 0.3216\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2599 - val_loss: 0.3001\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2766 - val_loss: 0.3040\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2782 - val_loss: 0.3208\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.2727 - val_loss: 0.3061\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.2763 - val_loss: 0.3179\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.2629 - val_loss: 0.3078\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.2782 - val_loss: 0.3088\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2659 - val_loss: 0.3126\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.2724 - val_loss: 0.3094\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.2693 - val_loss: 0.3219\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2521 - val_loss: 0.3159\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.2717 - val_loss: 0.3045\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2745 - val_loss: 0.3000\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.2666 - val_loss: 0.3108\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.2779 - val_loss: 0.3034\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.2637 - val_loss: 0.2989\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.2678 - val_loss: 0.2982\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.2612 - val_loss: 0.3027\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2553 - val_loss: 0.3039\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2590 - val_loss: 0.3456\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.2691 - val_loss: 0.3023\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.2763 - val_loss: 0.3010\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.2814 - val_loss: 0.3016\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 990us/step - loss: 1.7822 - val_loss: 0.5740\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.5535 - val_loss: 0.5533\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.5655 - val_loss: 0.5150\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.5411 - val_loss: 0.4622\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4491 - val_loss: 0.4559\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4269 - val_loss: 0.4452\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4801 - val_loss: 0.4301\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - loss: 0.4095 - val_loss: 0.4159\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.3873 - val_loss: 0.4100\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.4032 - val_loss: 0.4048\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3874 - val_loss: 0.4070\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.3776 - val_loss: 0.3914\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3857 - val_loss: 0.3850\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - loss: 0.3631 - val_loss: 0.3839\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.3856 - val_loss: 0.3753\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3836 - val_loss: 0.3803\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3535 - val_loss: 0.3700\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3505 - val_loss: 0.3782\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3413 - val_loss: 0.3642\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3285 - val_loss: 0.3726\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3396 - val_loss: 0.3691\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3424 - val_loss: 0.3752\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.3227 - val_loss: 0.3599\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3460 - val_loss: 0.3588\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3219 - val_loss: 0.3496\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3293 - val_loss: 0.3490\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3203 - val_loss: 0.3440\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3274 - val_loss: 0.3418\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.3302 - val_loss: 0.3506\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.3321 - val_loss: 0.3422\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.3123 - val_loss: 0.3468\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3263 - val_loss: 0.3413\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - loss: 0.3203 - val_loss: 0.3347\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 777us/step - loss: 0.3125 - val_loss: 0.3623\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3865 - val_loss: 0.3433\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3202 - val_loss: 0.3402\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3162 - val_loss: 0.3268\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3067 - val_loss: 0.3325\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.3089 - val_loss: 0.3223\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3030 - val_loss: 0.3278\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.2975 - val_loss: 0.3330\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3199 - val_loss: 0.3382\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.2904 - val_loss: 0.3335\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3101 - val_loss: 0.3213\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.2951 - val_loss: 0.3237\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3003 - val_loss: 0.3189\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.2979 - val_loss: 0.3269\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.2832 - val_loss: 0.3193\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3005 - val_loss: 0.3315\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2867 - val_loss: 0.3163\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.2796 - val_loss: 0.3428\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.2832 - val_loss: 0.3146\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.2876 - val_loss: 0.3145\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3011 - val_loss: 0.3620\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.2910 - val_loss: 0.3130\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.2901 - val_loss: 0.3175\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.2862 - val_loss: 0.3157\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2861 - val_loss: 0.3140\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.2898 - val_loss: 0.3200\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.2765 - val_loss: 0.3101\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.2680 - val_loss: 0.3295\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2812 - val_loss: 0.3290\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2846 - val_loss: 0.3126\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.2709 - val_loss: 0.3104\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.2730 - val_loss: 0.3128\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.2808 - val_loss: 0.3189\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.2610 - val_loss: 0.3168\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - loss: 0.2686 - val_loss: 0.3104\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.2757 - val_loss: 0.3120\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.2830 - val_loss: 0.3136\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.2692 - val_loss: 0.3152\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.2735 - val_loss: 0.3134\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.2648 - val_loss: 0.3198\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.2780 - val_loss: 0.3152\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.2830 - val_loss: 0.3033\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.2682 - val_loss: 0.3045\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.2719 - val_loss: 0.3066\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2628 - val_loss: 0.3160\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2838 - val_loss: 0.3072\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.2765 - val_loss: 0.3024\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.2568 - val_loss: 0.3062\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.2718 - val_loss: 0.3274\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.2664 - val_loss: 0.3153\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.2800 - val_loss: 0.3130\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.2723 - val_loss: 0.3247\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2645 - val_loss: 0.3095\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2683 - val_loss: 0.3034\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.2759 - val_loss: 0.3300\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.2738 - val_loss: 0.3133\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.2536 - val_loss: 0.3082\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.2594 - val_loss: 0.3347\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.2621 - val_loss: 0.3009\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.2647 - val_loss: 0.3162\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.2655 - val_loss: 0.3223\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2604 - val_loss: 0.3091\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.2526 - val_loss: 0.3002\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.2772 - val_loss: 0.3043\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - loss: 0.2528 - val_loss: 0.3028\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.2603 - val_loss: 0.3050\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.2518 - val_loss: 0.3041\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 867us/step - loss: 8.7661 - val_loss: 6.2882\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 6.6614 - val_loss: 4.7328\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 4.4135 - val_loss: 3.6440\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 3.7445 - val_loss: 2.8688\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 2.9081 - val_loss: 2.3094\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 2.4777 - val_loss: 1.8997\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 2.0271 - val_loss: 1.5969\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 1.5671 - val_loss: 1.3710\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 1.4352 - val_loss: 1.2014\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 1.2088 - val_loss: 1.0727\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.9768 - val_loss: 0.9745\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.9519 - val_loss: 0.8994\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 574us/step - loss: 0.8396 - val_loss: 0.8414\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.8156 - val_loss: 0.7963\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.8099 - val_loss: 0.7612\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.7174 - val_loss: 0.7336\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.7063 - val_loss: 0.7117\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.6781 - val_loss: 0.6943\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.6465 - val_loss: 0.6803\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.6510 - val_loss: 0.6689\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6231 - val_loss: 0.6597\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6399 - val_loss: 0.6519\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.6451 - val_loss: 0.6455\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.6260 - val_loss: 0.6400\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6278 - val_loss: 0.6353\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 0.6180 - val_loss: 0.6313\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.6100 - val_loss: 0.6277\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5946 - val_loss: 0.6245\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.6240 - val_loss: 0.6216\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5915 - val_loss: 0.6190\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5741 - val_loss: 0.6166\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5761 - val_loss: 0.6144\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.6240 - val_loss: 0.6124\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5849 - val_loss: 0.6104\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5924 - val_loss: 0.6086\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6007 - val_loss: 0.6069\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.5740 - val_loss: 0.6051\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.5844 - val_loss: 0.6036\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.6286 - val_loss: 0.6020\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.5922 - val_loss: 0.6005\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5753 - val_loss: 0.5991\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5629 - val_loss: 0.5977\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5812 - val_loss: 0.5964\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.5931 - val_loss: 0.5950\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 565us/step - loss: 0.5733 - val_loss: 0.5938\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5859 - val_loss: 0.5925\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5776 - val_loss: 0.5913\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 560us/step - loss: 0.5890 - val_loss: 0.5901\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5756 - val_loss: 0.5890\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.5780 - val_loss: 0.5878\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 0.5715 - val_loss: 0.5867\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 567us/step - loss: 0.5499 - val_loss: 0.5857\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.5734 - val_loss: 0.5846\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.5856 - val_loss: 0.5836\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 567us/step - loss: 0.5668 - val_loss: 0.5826\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.5775 - val_loss: 0.5816\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.5625 - val_loss: 0.5807\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5724 - val_loss: 0.5797\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5667 - val_loss: 0.5788\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5446 - val_loss: 0.5779\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5732 - val_loss: 0.5771\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5660 - val_loss: 0.5762\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5500 - val_loss: 0.5754\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5627 - val_loss: 0.5745\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5729 - val_loss: 0.5737\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5523 - val_loss: 0.5729\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5578 - val_loss: 0.5722\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5923 - val_loss: 0.5715\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5532 - val_loss: 0.5707\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5352 - val_loss: 0.5700\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5505 - val_loss: 0.5692\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5443 - val_loss: 0.5685\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5561 - val_loss: 0.5679\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 569us/step - loss: 0.5249 - val_loss: 0.5672\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5583 - val_loss: 0.5666\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5544 - val_loss: 0.5660\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.5544 - val_loss: 0.5653\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.5447 - val_loss: 0.5647\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5106 - val_loss: 0.5642\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 563us/step - loss: 0.5674 - val_loss: 0.5636\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 567us/step - loss: 0.5464 - val_loss: 0.5630\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5332 - val_loss: 0.5625\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.5489 - val_loss: 0.5619\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.5452 - val_loss: 0.5614\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5539 - val_loss: 0.5609\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5422 - val_loss: 0.5603\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5245 - val_loss: 0.5598\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5160 - val_loss: 0.5593\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 0.5486 - val_loss: 0.5588\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.5337 - val_loss: 0.5584\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5390 - val_loss: 0.5579\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5264 - val_loss: 0.5575\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.5346 - val_loss: 0.5570\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5583 - val_loss: 0.5567\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5286 - val_loss: 0.5563\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5472 - val_loss: 0.5558\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5550 - val_loss: 0.5555\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5359 - val_loss: 0.5551\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5295 - val_loss: 0.5547\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.5265 - val_loss: 0.5544\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 425us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - loss: 5.8392 - val_loss: 4.6886\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 565us/step - loss: 4.4879 - val_loss: 3.6732\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 3.5676 - val_loss: 2.9155\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558us/step - loss: 2.7560 - val_loss: 2.3482\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 2.2540 - val_loss: 1.9214\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 1.7952 - val_loss: 1.5989\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 562us/step - loss: 1.5616 - val_loss: 1.3550\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 565us/step - loss: 1.4138 - val_loss: 1.1697\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 1.1265 - val_loss: 1.0284\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.9909 - val_loss: 0.9206\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.9753 - val_loss: 0.8377\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.8507 - val_loss: 0.7740\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.7332 - val_loss: 0.7248\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.7304 - val_loss: 0.6867\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.6749 - val_loss: 0.6570\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.6047 - val_loss: 0.6338\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.6208 - val_loss: 0.6156\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.6297 - val_loss: 0.6014\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.5862 - val_loss: 0.5900\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.6296 - val_loss: 0.5810\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.6028 - val_loss: 0.5738\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 563us/step - loss: 0.5723 - val_loss: 0.5680\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5938 - val_loss: 0.5634\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5336 - val_loss: 0.5597\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5437 - val_loss: 0.5565\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5350 - val_loss: 0.5540\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5683 - val_loss: 0.5519\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5346 - val_loss: 0.5502\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5610 - val_loss: 0.5488\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 560us/step - loss: 0.5408 - val_loss: 0.5475\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: 0.5337 - val_loss: 0.5465\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.5454 - val_loss: 0.5456\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5501 - val_loss: 0.5449\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556us/step - loss: 0.5382 - val_loss: 0.5443\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5447 - val_loss: 0.5438\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5443 - val_loss: 0.5434\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5149 - val_loss: 0.5430\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5559 - val_loss: 0.5427\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5387 - val_loss: 0.5423\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5414 - val_loss: 0.5420\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.5104 - val_loss: 0.5418\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5470 - val_loss: 0.5417\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5229 - val_loss: 0.5416\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 0.5264 - val_loss: 0.5414\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 0.5557 - val_loss: 0.5411\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5241 - val_loss: 0.5410\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5179 - val_loss: 0.5410\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5000 - val_loss: 0.5408\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5419 - val_loss: 0.5406\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5735 - val_loss: 0.5405\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 563us/step - loss: 0.5309 - val_loss: 0.5404\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559us/step - loss: 0.5015 - val_loss: 0.5404\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 570us/step - loss: 0.5105 - val_loss: 0.5404\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5226 - val_loss: 0.5402\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5553 - val_loss: 0.5402\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5321 - val_loss: 0.5400\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5062 - val_loss: 0.5399\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.5339 - val_loss: 0.5400\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.5161 - val_loss: 0.5399\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.5390 - val_loss: 0.5398\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5187 - val_loss: 0.5398\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5458 - val_loss: 0.5398\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - loss: 0.5265 - val_loss: 0.5397\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 562us/step - loss: 0.5237 - val_loss: 0.5396\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5529 - val_loss: 0.5395\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.5471 - val_loss: 0.5394\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5227 - val_loss: 0.5394\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5239 - val_loss: 0.5393\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.5228 - val_loss: 0.5393\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5293 - val_loss: 0.5393\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5624 - val_loss: 0.5392\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.5037 - val_loss: 0.5392\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5407 - val_loss: 0.5393\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5566 - val_loss: 0.5392\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.5384 - val_loss: 0.5392\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.5398 - val_loss: 0.5393\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5423 - val_loss: 0.5392\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5217 - val_loss: 0.5392\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5459 - val_loss: 0.5392\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.5311 - val_loss: 0.5391\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5327 - val_loss: 0.5391\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5370 - val_loss: 0.5391\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5420 - val_loss: 0.5392\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5339 - val_loss: 0.5391\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5122 - val_loss: 0.5392\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5437 - val_loss: 0.5391\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5446 - val_loss: 0.5391\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5417 - val_loss: 0.5390\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5302 - val_loss: 0.5389\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5330 - val_loss: 0.5389\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5093 - val_loss: 0.5390\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5296 - val_loss: 0.5389\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5086 - val_loss: 0.5389\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5460 - val_loss: 0.5388\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5295 - val_loss: 0.5388\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5179 - val_loss: 0.5388\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5206 - val_loss: 0.5388\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5273 - val_loss: 0.5388\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5384 - val_loss: 0.5388\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5311 - val_loss: 0.5389\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 508us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 811us/step - loss: 6.3013 - val_loss: 4.6654\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 4.5297 - val_loss: 3.6339\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 3.5272 - val_loss: 2.8855\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 2.7820 - val_loss: 2.3392\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 2.2718 - val_loss: 1.9380\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 1.8565 - val_loss: 1.6421\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 1.5891 - val_loss: 1.4230\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 1.3600 - val_loss: 1.2599\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 1.2707 - val_loss: 1.1381\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 1.0998 - val_loss: 1.0468\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 1.0221 - val_loss: 0.9778\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.9444 - val_loss: 0.9256\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.9366 - val_loss: 0.8857\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.8992 - val_loss: 0.8547\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.8260 - val_loss: 0.8306\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.7888 - val_loss: 0.8114\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.7872 - val_loss: 0.7960\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.7723 - val_loss: 0.7835\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.7718 - val_loss: 0.7730\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.7904 - val_loss: 0.7642\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.7531 - val_loss: 0.7566\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.7654 - val_loss: 0.7498\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.7550 - val_loss: 0.7437\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.7562 - val_loss: 0.7382\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.7222 - val_loss: 0.7331\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.7354 - val_loss: 0.7284\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.7300 - val_loss: 0.7239\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.7060 - val_loss: 0.7197\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.7056 - val_loss: 0.7156\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.7312 - val_loss: 0.7117\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.6765 - val_loss: 0.7079\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.6851 - val_loss: 0.7042\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.6686 - val_loss: 0.7006\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.7025 - val_loss: 0.6972\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 567us/step - loss: 0.6720 - val_loss: 0.6938\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.6851 - val_loss: 0.6905\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6824 - val_loss: 0.6873\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.6691 - val_loss: 0.6842\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.7017 - val_loss: 0.6811\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6695 - val_loss: 0.6781\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6767 - val_loss: 0.6752\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6871 - val_loss: 0.6723\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6709 - val_loss: 0.6695\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 655us/step - loss: 0.6715 - val_loss: 0.6668\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 645us/step - loss: 0.6499 - val_loss: 0.6641\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6606 - val_loss: 0.6615\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.6613 - val_loss: 0.6590\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.6465 - val_loss: 0.6565\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6187 - val_loss: 0.6540\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6191 - val_loss: 0.6517\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6502 - val_loss: 0.6493\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6588 - val_loss: 0.6470\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.6430 - val_loss: 0.6448\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.6502 - val_loss: 0.6426\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.6436 - val_loss: 0.6405\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.6321 - val_loss: 0.6384\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.6075 - val_loss: 0.6364\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.6229 - val_loss: 0.6343\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.6099 - val_loss: 0.6324\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6011 - val_loss: 0.6305\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6124 - val_loss: 0.6286\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6133 - val_loss: 0.6268\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.6474 - val_loss: 0.6250\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6055 - val_loss: 0.6232\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.6192 - val_loss: 0.6215\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6266 - val_loss: 0.6198\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6151 - val_loss: 0.6182\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6010 - val_loss: 0.6166\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6232 - val_loss: 0.6150\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6025 - val_loss: 0.6134\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5892 - val_loss: 0.6119\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5994 - val_loss: 0.6104\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.6172 - val_loss: 0.6090\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.6072 - val_loss: 0.6076\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.6083 - val_loss: 0.6062\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.5773 - val_loss: 0.6049\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5911 - val_loss: 0.6036\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.6148 - val_loss: 0.6023\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5883 - val_loss: 0.6010\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5934 - val_loss: 0.5997\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6061 - val_loss: 0.5986\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5814 - val_loss: 0.5974\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5788 - val_loss: 0.5962\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6095 - val_loss: 0.5951\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5950 - val_loss: 0.5940\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.6297 - val_loss: 0.5929\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.5967 - val_loss: 0.5918\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.5849 - val_loss: 0.5908\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5922 - val_loss: 0.5897\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5943 - val_loss: 0.5887\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5780 - val_loss: 0.5877\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.5731 - val_loss: 0.5868\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5751 - val_loss: 0.5858\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5674 - val_loss: 0.5849\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6000 - val_loss: 0.5840\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5824 - val_loss: 0.5831\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5504 - val_loss: 0.5822\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5675 - val_loss: 0.5814\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5589 - val_loss: 0.5806\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5813 - val_loss: 0.5798\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - loss: 2.4583 - val_loss: 0.7300\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.7632 - val_loss: 0.6516\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.6370 - val_loss: 0.6024\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.5552 - val_loss: 0.5653\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.5498 - val_loss: 0.5392\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.5176 - val_loss: 0.5202\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.5093 - val_loss: 0.5071\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.4916 - val_loss: 0.4957\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.4753 - val_loss: 0.4882\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.4606 - val_loss: 0.4804\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.4464 - val_loss: 0.4753\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.4329 - val_loss: 0.4677\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.4202 - val_loss: 0.4623\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.4199 - val_loss: 0.4595\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.4304 - val_loss: 0.4595\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4182 - val_loss: 0.4523\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4264 - val_loss: 0.4490\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.4094 - val_loss: 0.4455\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.4417 - val_loss: 0.4419\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.4159 - val_loss: 0.4394\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.4224 - val_loss: 0.4424\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.3844 - val_loss: 0.4337\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.3999 - val_loss: 0.4326\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.4153 - val_loss: 0.4328\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.4016 - val_loss: 0.4293\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 0.4051 - val_loss: 0.4263\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3848 - val_loss: 0.4235\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.4038 - val_loss: 0.4256\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.3913 - val_loss: 0.4199\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 0.3993 - val_loss: 0.4211\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 0.3837 - val_loss: 0.4168\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3849 - val_loss: 0.4202\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3936 - val_loss: 0.4155\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3838 - val_loss: 0.4169\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4014 - val_loss: 0.4133\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3898 - val_loss: 0.4116\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.3952 - val_loss: 0.4090\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3720 - val_loss: 0.4104\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 0.3792 - val_loss: 0.4119\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3803 - val_loss: 0.4076\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3659 - val_loss: 0.4047\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.3707 - val_loss: 0.4074\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3655 - val_loss: 0.4224\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3982 - val_loss: 0.4167\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.4050 - val_loss: 0.4089\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3844 - val_loss: 0.4030\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3736 - val_loss: 0.3976\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 0.3901 - val_loss: 0.4023\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3667 - val_loss: 0.3952\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 0.3691 - val_loss: 0.3960\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.3759 - val_loss: 0.3921\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3691 - val_loss: 0.3963\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3781 - val_loss: 0.3907\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.3502 - val_loss: 0.3929\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3590 - val_loss: 0.3891\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.3762 - val_loss: 0.3906\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3749 - val_loss: 0.3878\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - loss: 0.3507 - val_loss: 0.3877\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3523 - val_loss: 0.3857\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3483 - val_loss: 0.3860\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3651 - val_loss: 0.3833\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 0.3480 - val_loss: 0.3856\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.3454 - val_loss: 0.3816\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.3516 - val_loss: 0.3829\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3441 - val_loss: 0.3797\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3515 - val_loss: 0.3848\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3605 - val_loss: 0.3781\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3525 - val_loss: 0.3898\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3451 - val_loss: 0.3809\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3606 - val_loss: 0.3854\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3552 - val_loss: 0.3742\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3522 - val_loss: 0.3793\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3541 - val_loss: 0.3741\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3528 - val_loss: 0.3761\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3378 - val_loss: 0.3728\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3477 - val_loss: 0.3750\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.3414 - val_loss: 0.3722\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3381 - val_loss: 0.3804\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.3551 - val_loss: 0.3734\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3417 - val_loss: 0.3724\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.3528 - val_loss: 0.3687\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3324 - val_loss: 0.3727\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 0.3408 - val_loss: 0.3694\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3517 - val_loss: 0.3706\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3337 - val_loss: 0.3695\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3434 - val_loss: 0.3674\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3367 - val_loss: 0.3650\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3317 - val_loss: 0.3653\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.3400 - val_loss: 0.3651\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3317 - val_loss: 0.3786\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3355 - val_loss: 0.3650\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3227 - val_loss: 0.3635\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3561 - val_loss: 0.3617\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.3388 - val_loss: 0.3622\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.3370 - val_loss: 0.3615\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 761us/step - loss: 0.3455 - val_loss: 0.3618\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3400 - val_loss: 0.3622\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.3375 - val_loss: 0.3627\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3484 - val_loss: 0.3622\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3466 - val_loss: 0.3719\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 935us/step - loss: 2.2690 - val_loss: 0.7261\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.6745 - val_loss: 0.6451\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.6099 - val_loss: 0.6021\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.5563 - val_loss: 0.5698\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.5577 - val_loss: 0.5482\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.5465 - val_loss: 0.5306\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.5245 - val_loss: 0.5163\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.5136 - val_loss: 0.5048\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.4782 - val_loss: 0.4960\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.4869 - val_loss: 0.4867\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.4768 - val_loss: 0.4805\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4659 - val_loss: 0.4754\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.4518 - val_loss: 0.4680\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.4633 - val_loss: 0.4633\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.4464 - val_loss: 0.4604\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4512 - val_loss: 0.4562\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.4466 - val_loss: 0.4507\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.4428 - val_loss: 0.4464\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.4429 - val_loss: 0.4432\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.4260 - val_loss: 0.4402\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.4220 - val_loss: 0.4389\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.4104 - val_loss: 0.4343\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4190 - val_loss: 0.4339\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4228 - val_loss: 0.4289\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4170 - val_loss: 0.4280\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4193 - val_loss: 0.4256\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.4123 - val_loss: 0.4233\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.4229 - val_loss: 0.4211\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3998 - val_loss: 0.4193\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.4016 - val_loss: 0.4175\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3875 - val_loss: 0.4155\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3992 - val_loss: 0.4131\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3832 - val_loss: 0.4126\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.3871 - val_loss: 0.4107\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.3988 - val_loss: 0.4097\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - loss: 0.3926 - val_loss: 0.4084\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3927 - val_loss: 0.4053\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3824 - val_loss: 0.4041\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.4032 - val_loss: 0.4040\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3682 - val_loss: 0.4023\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3687 - val_loss: 0.4008\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3768 - val_loss: 0.4019\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3752 - val_loss: 0.3981\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3942 - val_loss: 0.3966\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.3875 - val_loss: 0.3945\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3812 - val_loss: 0.3932\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 0.4015 - val_loss: 0.3923\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3746 - val_loss: 0.3906\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3593 - val_loss: 0.3925\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3727 - val_loss: 0.3873\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.3624 - val_loss: 0.3895\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3741 - val_loss: 0.3856\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3691 - val_loss: 0.3862\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - loss: 0.3556 - val_loss: 0.3843\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.3681 - val_loss: 0.3819\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3755 - val_loss: 0.3823\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3542 - val_loss: 0.3812\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3652 - val_loss: 0.3783\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3703 - val_loss: 0.3773\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3625 - val_loss: 0.3765\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.3666 - val_loss: 0.3757\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3365 - val_loss: 0.3740\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3590 - val_loss: 0.3761\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3570 - val_loss: 0.3720\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3308 - val_loss: 0.3721\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3447 - val_loss: 0.3697\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3577 - val_loss: 0.3709\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3433 - val_loss: 0.3676\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3617 - val_loss: 0.3708\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3580 - val_loss: 0.3669\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.3525 - val_loss: 0.3673\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 0.3350 - val_loss: 0.3669\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.3410 - val_loss: 0.3648\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3545 - val_loss: 0.3640\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 0.3544 - val_loss: 0.3633\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3397 - val_loss: 0.3629\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3409 - val_loss: 0.3611\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3406 - val_loss: 0.3656\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3359 - val_loss: 0.3605\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3592 - val_loss: 0.3592\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.3385 - val_loss: 0.3578\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3381 - val_loss: 0.3573\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.3418 - val_loss: 0.3573\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3319 - val_loss: 0.3555\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3504 - val_loss: 0.3560\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3334 - val_loss: 0.3557\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.3390 - val_loss: 0.3535\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3411 - val_loss: 0.3525\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3141 - val_loss: 0.3538\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3129 - val_loss: 0.3543\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3252 - val_loss: 0.3519\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3256 - val_loss: 0.3510\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3257 - val_loss: 0.3513\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3130 - val_loss: 0.3496\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3292 - val_loss: 0.3487\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3176 - val_loss: 0.3476\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3167 - val_loss: 0.3493\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3181 - val_loss: 0.3464\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3055 - val_loss: 0.3470\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 959us/step - loss: 2.3070 - val_loss: 0.7578\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.7103 - val_loss: 0.6730\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.6585 - val_loss: 0.6263\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.5780 - val_loss: 0.5933\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.5959 - val_loss: 0.5666\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.5442 - val_loss: 0.5456\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.5307 - val_loss: 0.5294\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.5317 - val_loss: 0.5142\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 770us/step - loss: 0.4878 - val_loss: 0.5028\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.4789 - val_loss: 0.4920\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.4797 - val_loss: 0.4845\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4497 - val_loss: 0.4767\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4550 - val_loss: 0.4698\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.4375 - val_loss: 0.4647\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4660 - val_loss: 0.4597\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.4467 - val_loss: 0.4564\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 0.4462 - val_loss: 0.4513\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.4424 - val_loss: 0.4479\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.4175 - val_loss: 0.4448\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4295 - val_loss: 0.4420\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.4088 - val_loss: 0.4398\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.4293 - val_loss: 0.4368\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.4216 - val_loss: 0.4341\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.4262 - val_loss: 0.4330\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.4097 - val_loss: 0.4297\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4250 - val_loss: 0.4289\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3982 - val_loss: 0.4255\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.3946 - val_loss: 0.4243\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.4252 - val_loss: 0.4223\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.4092 - val_loss: 0.4201\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4213 - val_loss: 0.4213\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3900 - val_loss: 0.4170\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3920 - val_loss: 0.4151\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4060 - val_loss: 0.4131\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4007 - val_loss: 0.4123\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.3967 - val_loss: 0.4097\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3917 - val_loss: 0.4083\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3955 - val_loss: 0.4075\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - loss: 0.3729 - val_loss: 0.4064\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.3802 - val_loss: 0.4063\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3836 - val_loss: 0.4033\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.3671 - val_loss: 0.4030\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3918 - val_loss: 0.4005\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3797 - val_loss: 0.3988\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.3825 - val_loss: 0.3972\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3800 - val_loss: 0.3963\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3776 - val_loss: 0.3956\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3571 - val_loss: 0.3943\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3812 - val_loss: 0.3936\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 0.3783 - val_loss: 0.3911\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3696 - val_loss: 0.3900\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3760 - val_loss: 0.3903\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.3586 - val_loss: 0.3885\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3590 - val_loss: 0.3878\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3739 - val_loss: 0.3853\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 0.3793 - val_loss: 0.3859\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3636 - val_loss: 0.3843\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3539 - val_loss: 0.3822\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3801 - val_loss: 0.3840\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.3677 - val_loss: 0.3807\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3540 - val_loss: 0.3803\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 0.3623 - val_loss: 0.3781\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.3502 - val_loss: 0.3767\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3683 - val_loss: 0.3759\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3530 - val_loss: 0.3758\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3613 - val_loss: 0.3759\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3558 - val_loss: 0.3725\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3607 - val_loss: 0.3740\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 0.3542 - val_loss: 0.3708\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3363 - val_loss: 0.3701\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.3604 - val_loss: 0.3715\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3419 - val_loss: 0.3684\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3456 - val_loss: 0.3692\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3407 - val_loss: 0.3688\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.3563 - val_loss: 0.3675\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3427 - val_loss: 0.3660\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3294 - val_loss: 0.3658\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3428 - val_loss: 0.3649\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.3510 - val_loss: 0.3658\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3511 - val_loss: 0.3626\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 770us/step - loss: 0.3554 - val_loss: 0.3619\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3490 - val_loss: 0.3619\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.3386 - val_loss: 0.3607\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3473 - val_loss: 0.3591\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 0.3435 - val_loss: 0.3604\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3556 - val_loss: 0.3638\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3473 - val_loss: 0.3578\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.3549 - val_loss: 0.3562\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3469 - val_loss: 0.3568\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 0.3382 - val_loss: 0.3553\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.3312 - val_loss: 0.3576\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3233 - val_loss: 0.3560\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3313 - val_loss: 0.3527\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.3223 - val_loss: 0.3537\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.3258 - val_loss: 0.3528\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3253 - val_loss: 0.3524\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3154 - val_loss: 0.3498\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 0.3212 - val_loss: 0.3513\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3351 - val_loss: 0.3506\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3274 - val_loss: 0.3499\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 979us/step - loss: 4.4245 - val_loss: 1.3617\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 1.2080 - val_loss: 0.9173\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.8659 - val_loss: 0.7730\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.7414 - val_loss: 0.7122\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.6763 - val_loss: 0.6787\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.6549 - val_loss: 0.6561\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.6553 - val_loss: 0.6389\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.6569 - val_loss: 0.6237\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.6023 - val_loss: 0.6100\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.5886 - val_loss: 0.5978\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.5512 - val_loss: 0.5862\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.5782 - val_loss: 0.5757\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.5816 - val_loss: 0.5656\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - loss: 0.5464 - val_loss: 0.5565\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - loss: 0.5291 - val_loss: 0.5484\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step - loss: 0.5163 - val_loss: 0.5400\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.5372 - val_loss: 0.5326\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.4955 - val_loss: 0.5268\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - loss: 0.4984 - val_loss: 0.5196\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4987 - val_loss: 0.5137\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4999 - val_loss: 0.5084\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4835 - val_loss: 0.5045\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.4937 - val_loss: 0.4990\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4703 - val_loss: 0.4949\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4925 - val_loss: 0.4910\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4601 - val_loss: 0.4874\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4538 - val_loss: 0.4841\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.4617 - val_loss: 0.4808\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4961 - val_loss: 0.4781\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.4520 - val_loss: 0.4752\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4714 - val_loss: 0.4728\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4459 - val_loss: 0.4700\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.4467 - val_loss: 0.4684\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - loss: 0.4411 - val_loss: 0.4655\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.4369 - val_loss: 0.4635\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - loss: 0.4124 - val_loss: 0.4615\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step - loss: 0.4540 - val_loss: 0.4595\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 741us/step - loss: 0.4276 - val_loss: 0.4578\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4167 - val_loss: 0.4557\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4336 - val_loss: 0.4541\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.4234 - val_loss: 0.4524\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4306 - val_loss: 0.4512\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 746us/step - loss: 0.4381 - val_loss: 0.4512\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 795us/step - loss: 0.4384 - val_loss: 0.4479\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.4155 - val_loss: 0.4464\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4201 - val_loss: 0.4452\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.4246 - val_loss: 0.4436\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3970 - val_loss: 0.4425\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4154 - val_loss: 0.4414\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4002 - val_loss: 0.4400\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - loss: 0.4135 - val_loss: 0.4394\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4107 - val_loss: 0.4384\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3969 - val_loss: 0.4366\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4150 - val_loss: 0.4350\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4068 - val_loss: 0.4338\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4015 - val_loss: 0.4329\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3968 - val_loss: 0.4318\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - loss: 0.4000 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - loss: 0.3978 - val_loss: 0.4297\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.4040 - val_loss: 0.4290\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.3981 - val_loss: 0.4277\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.4042 - val_loss: 0.4271\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3975 - val_loss: 0.4259\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4071 - val_loss: 0.4255\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3968 - val_loss: 0.4243\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3979 - val_loss: 0.4235\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3746 - val_loss: 0.4223\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4113 - val_loss: 0.4217\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.3835 - val_loss: 0.4208\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3919 - val_loss: 0.4210\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3924 - val_loss: 0.4208\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3962 - val_loss: 0.4180\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3839 - val_loss: 0.4175\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step - loss: 0.3880 - val_loss: 0.4166\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3903 - val_loss: 0.4158\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4143 - val_loss: 0.4154\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.3869 - val_loss: 0.4143\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - loss: 0.3868 - val_loss: 0.4154\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 741us/step - loss: 0.3846 - val_loss: 0.4131\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - loss: 0.3832 - val_loss: 0.4123\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3811 - val_loss: 0.4115\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - loss: 0.3836 - val_loss: 0.4105\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.3863 - val_loss: 0.4103\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3761 - val_loss: 0.4091\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3760 - val_loss: 0.4085\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.3870 - val_loss: 0.4082\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3659 - val_loss: 0.4073\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - loss: 0.3854 - val_loss: 0.4065\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 784us/step - loss: 0.3635 - val_loss: 0.4060\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3738 - val_loss: 0.4059\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3825 - val_loss: 0.4051\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 0.3655 - val_loss: 0.4045\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3744 - val_loss: 0.4042\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.3752 - val_loss: 0.4027\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.3800 - val_loss: 0.4020\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3724 - val_loss: 0.4020\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.3627 - val_loss: 0.4009\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3602 - val_loss: 0.4008\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - loss: 0.3668 - val_loss: 0.4001\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.3892 - val_loss: 0.3998\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 3.1524 - val_loss: 1.1560\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - loss: 1.0702 - val_loss: 0.8724\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.7984 - val_loss: 0.7757\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - loss: 0.7619 - val_loss: 0.7287\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.7099 - val_loss: 0.6976\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.6959 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.6514 - val_loss: 0.6552\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.6220 - val_loss: 0.6390\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - loss: 0.6399 - val_loss: 0.6233\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.6097 - val_loss: 0.6097\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.6235 - val_loss: 0.5973\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 795us/step - loss: 0.5816 - val_loss: 0.5866\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.5910 - val_loss: 0.5757\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.5541 - val_loss: 0.5660\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.5433 - val_loss: 0.5571\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.5495 - val_loss: 0.5490\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.5371 - val_loss: 0.5413\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.5054 - val_loss: 0.5342\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.5086 - val_loss: 0.5277\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.5232 - val_loss: 0.5217\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4916 - val_loss: 0.5163\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4995 - val_loss: 0.5108\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - loss: 0.4701 - val_loss: 0.5060\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4791 - val_loss: 0.5015\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4930 - val_loss: 0.4975\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4810 - val_loss: 0.4938\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4812 - val_loss: 0.4896\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.4855 - val_loss: 0.4862\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4789 - val_loss: 0.4830\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4399 - val_loss: 0.4798\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4491 - val_loss: 0.4765\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4623 - val_loss: 0.4747\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.4666 - val_loss: 0.4711\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4727 - val_loss: 0.4686\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4421 - val_loss: 0.4661\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4395 - val_loss: 0.4640\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.4388 - val_loss: 0.4619\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.4585 - val_loss: 0.4598\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.4326 - val_loss: 0.4577\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4378 - val_loss: 0.4562\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4250 - val_loss: 0.4543\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4194 - val_loss: 0.4530\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 822us/step - loss: 0.4254 - val_loss: 0.4508\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.4195 - val_loss: 0.4494\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4357 - val_loss: 0.4475\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.4252 - val_loss: 0.4462\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.4178 - val_loss: 0.4445\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.4378 - val_loss: 0.4431\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.4228 - val_loss: 0.4419\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4169 - val_loss: 0.4407\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4204 - val_loss: 0.4400\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.4140 - val_loss: 0.4383\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4051 - val_loss: 0.4371\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - loss: 0.4107 - val_loss: 0.4360\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.4157 - val_loss: 0.4349\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4055 - val_loss: 0.4336\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4195 - val_loss: 0.4328\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 0.4301 - val_loss: 0.4319\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4022 - val_loss: 0.4307\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - loss: 0.4216 - val_loss: 0.4299\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4230 - val_loss: 0.4291\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - loss: 0.4048 - val_loss: 0.4279\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - loss: 0.4150 - val_loss: 0.4270\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.4077 - val_loss: 0.4265\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4171 - val_loss: 0.4258\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3902 - val_loss: 0.4247\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4074 - val_loss: 0.4237\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4059 - val_loss: 0.4229\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.3950 - val_loss: 0.4224\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - loss: 0.3954 - val_loss: 0.4212\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - loss: 0.4008 - val_loss: 0.4208\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4175 - val_loss: 0.4196\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.3967 - val_loss: 0.4189\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - loss: 0.3972 - val_loss: 0.4183\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3939 - val_loss: 0.4176\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - loss: 0.4055 - val_loss: 0.4169\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4016 - val_loss: 0.4166\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4002 - val_loss: 0.4154\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.4019 - val_loss: 0.4148\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 774us/step - loss: 0.3924 - val_loss: 0.4140\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - loss: 0.3875 - val_loss: 0.4143\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3872 - val_loss: 0.4131\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4059 - val_loss: 0.4125\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3847 - val_loss: 0.4116\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - loss: 0.4007 - val_loss: 0.4109\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - loss: 0.4009 - val_loss: 0.4105\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - loss: 0.3820 - val_loss: 0.4098\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - loss: 0.3852 - val_loss: 0.4089\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3923 - val_loss: 0.4084\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3972 - val_loss: 0.4078\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3831 - val_loss: 0.4074\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.3857 - val_loss: 0.4067\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.3848 - val_loss: 0.4065\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3777 - val_loss: 0.4058\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3843 - val_loss: 0.4049\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - loss: 0.3928 - val_loss: 0.4045\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3754 - val_loss: 0.4038\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.3782 - val_loss: 0.4033\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - loss: 0.3869 - val_loss: 0.4027\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.3782 - val_loss: 0.4026\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 4.1147 - val_loss: 1.6950\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 1.4283 - val_loss: 1.0711\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - loss: 0.9809 - val_loss: 0.8550\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - loss: 0.8131 - val_loss: 0.7620\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.7217 - val_loss: 0.7168\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.7018 - val_loss: 0.6921\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.6739 - val_loss: 0.6738\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - loss: 0.6330 - val_loss: 0.6587\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - loss: 0.6377 - val_loss: 0.6452\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - loss: 0.6227 - val_loss: 0.6336\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.6355 - val_loss: 0.6217\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 772us/step - loss: 0.6283 - val_loss: 0.6109\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.5860 - val_loss: 0.6009\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.6066 - val_loss: 0.5919\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - loss: 0.5674 - val_loss: 0.5829\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.5752 - val_loss: 0.5747\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - loss: 0.5536 - val_loss: 0.5669\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.5864 - val_loss: 0.5596\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.5361 - val_loss: 0.5528\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.5482 - val_loss: 0.5464\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.5099 - val_loss: 0.5404\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - loss: 0.5229 - val_loss: 0.5352\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.5201 - val_loss: 0.5295\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.5194 - val_loss: 0.5245\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.5016 - val_loss: 0.5200\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.4900 - val_loss: 0.5154\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4967 - val_loss: 0.5113\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - loss: 0.4839 - val_loss: 0.5074\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4900 - val_loss: 0.5038\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - loss: 0.4945 - val_loss: 0.5004\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - loss: 0.4812 - val_loss: 0.4972\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4607 - val_loss: 0.4940\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.4752 - val_loss: 0.4911\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.4990 - val_loss: 0.4882\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 0.4674 - val_loss: 0.4858\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4650 - val_loss: 0.4830\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4626 - val_loss: 0.4806\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4620 - val_loss: 0.4783\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4626 - val_loss: 0.4761\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4502 - val_loss: 0.4741\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.4462 - val_loss: 0.4719\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4606 - val_loss: 0.4700\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4581 - val_loss: 0.4681\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.4422 - val_loss: 0.4662\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4577 - val_loss: 0.4647\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4390 - val_loss: 0.4628\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.4531 - val_loss: 0.4611\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4296 - val_loss: 0.4596\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - loss: 0.4380 - val_loss: 0.4579\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - loss: 0.4352 - val_loss: 0.4565\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - loss: 0.4428 - val_loss: 0.4554\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4372 - val_loss: 0.4534\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4397 - val_loss: 0.4521\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4776 - val_loss: 0.4506\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4412 - val_loss: 0.4493\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.4352 - val_loss: 0.4482\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4298 - val_loss: 0.4469\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 0.4134 - val_loss: 0.4455\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.4292 - val_loss: 0.4442\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4507 - val_loss: 0.4430\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4261 - val_loss: 0.4419\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4296 - val_loss: 0.4407\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - loss: 0.4480 - val_loss: 0.4395\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.4091 - val_loss: 0.4386\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4158 - val_loss: 0.4371\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4173 - val_loss: 0.4361\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4031 - val_loss: 0.4352\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4250 - val_loss: 0.4339\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4313 - val_loss: 0.4329\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4226 - val_loss: 0.4318\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.4206 - val_loss: 0.4308\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 759us/step - loss: 0.4117 - val_loss: 0.4298\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 770us/step - loss: 0.4092 - val_loss: 0.4290\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3974 - val_loss: 0.4278\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - loss: 0.4107 - val_loss: 0.4270\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4021 - val_loss: 0.4258\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4254 - val_loss: 0.4249\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4002 - val_loss: 0.4242\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - loss: 0.4119 - val_loss: 0.4233\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.3769 - val_loss: 0.4221\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 0.4236 - val_loss: 0.4215\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3966 - val_loss: 0.4202\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.3976 - val_loss: 0.4196\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - loss: 0.4016 - val_loss: 0.4186\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.4022 - val_loss: 0.4183\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.4064 - val_loss: 0.4170\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - loss: 0.3956 - val_loss: 0.4162\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - loss: 0.4054 - val_loss: 0.4152\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 0.3920 - val_loss: 0.4149\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - loss: 0.4045 - val_loss: 0.4136\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - loss: 0.4077 - val_loss: 0.4128\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.3884 - val_loss: 0.4122\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3960 - val_loss: 0.4113\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - loss: 0.3902 - val_loss: 0.4108\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.3921 - val_loss: 0.4096\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - loss: 0.3843 - val_loss: 0.4090\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - loss: 0.4091 - val_loss: 0.4085\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.3801 - val_loss: 0.4083\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3814 - val_loss: 0.4071\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3790 - val_loss: 0.4064\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 842us/step - loss: 4.7045 - val_loss: 1.1478\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.9999 - val_loss: 0.7430\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.7116 - val_loss: 0.6848\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6531 - val_loss: 0.6549\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6218 - val_loss: 0.6348\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.6022 - val_loss: 0.6181\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.6175 - val_loss: 0.6047\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 0.5723 - val_loss: 0.5930\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.5535 - val_loss: 0.5845\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.5589 - val_loss: 0.5765\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.5477 - val_loss: 0.5697\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.5152 - val_loss: 0.5644\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.5244 - val_loss: 0.5607\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5414 - val_loss: 0.5572\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5077 - val_loss: 0.5544\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.5160 - val_loss: 0.5510\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5348 - val_loss: 0.5500\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5235 - val_loss: 0.5480\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5310 - val_loss: 0.5470\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5154 - val_loss: 0.5447\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5257 - val_loss: 0.5440\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.5042 - val_loss: 0.5427\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5196 - val_loss: 0.5423\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5246 - val_loss: 0.5428\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5095 - val_loss: 0.5419\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5113 - val_loss: 0.5417\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5311 - val_loss: 0.5399\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5341 - val_loss: 0.5407\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5006 - val_loss: 0.5409\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5142 - val_loss: 0.5396\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5260 - val_loss: 0.5391\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.5066 - val_loss: 0.5399\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5242 - val_loss: 0.5385\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5211 - val_loss: 0.5378\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5185 - val_loss: 0.5381\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5188 - val_loss: 0.5377\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.4896 - val_loss: 0.5393\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5024 - val_loss: 0.5399\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5381 - val_loss: 0.5382\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5103 - val_loss: 0.5400\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.4882 - val_loss: 0.5376\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5073 - val_loss: 0.5378\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.4968 - val_loss: 0.5397\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5296 - val_loss: 0.5378\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5165 - val_loss: 0.5393\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5020 - val_loss: 0.5385\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5231 - val_loss: 0.5371\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5271 - val_loss: 0.5403\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5271 - val_loss: 0.5377\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5132 - val_loss: 0.5371\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5081 - val_loss: 0.5395\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5394 - val_loss: 0.5393\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5160 - val_loss: 0.5405\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5261 - val_loss: 0.5378\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5038 - val_loss: 0.5373\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5012 - val_loss: 0.5385\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5460 - val_loss: 0.5386\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5155 - val_loss: 0.5380\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5038 - val_loss: 0.5392\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5215 - val_loss: 0.5370\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.4980 - val_loss: 0.5378\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5140 - val_loss: 0.5374\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.5082 - val_loss: 0.5376\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5277 - val_loss: 0.5372\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5071 - val_loss: 0.5388\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.4894 - val_loss: 0.5378\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5243 - val_loss: 0.5407\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5094 - val_loss: 0.5406\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5201 - val_loss: 0.5377\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5137 - val_loss: 0.5393\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5077 - val_loss: 0.5409\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5072 - val_loss: 0.5380\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5278 - val_loss: 0.5372\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4887 - val_loss: 0.5386\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5220 - val_loss: 0.5391\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5260 - val_loss: 0.5407\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5093 - val_loss: 0.5370\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5198 - val_loss: 0.5391\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5272 - val_loss: 0.5396\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 0.5174 - val_loss: 0.5386\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5131 - val_loss: 0.5374\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5375 - val_loss: 0.5370\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5194 - val_loss: 0.5396\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5098 - val_loss: 0.5372\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5208 - val_loss: 0.5376\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5191 - val_loss: 0.5380\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.4974 - val_loss: 0.5370\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5376 - val_loss: 0.5373\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5058 - val_loss: 0.5402\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.5220 - val_loss: 0.5392\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5092 - val_loss: 0.5374\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5092 - val_loss: 0.5375\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5076 - val_loss: 0.5371\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.5228 - val_loss: 0.5380\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5217 - val_loss: 0.5401\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5318 - val_loss: 0.5369\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5030 - val_loss: 0.5391\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5263 - val_loss: 0.5402\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5374 - val_loss: 0.5390\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5182 - val_loss: 0.5387\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 508us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 903us/step - loss: 4.3308 - val_loss: 1.0024\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.8671 - val_loss: 0.6253\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6341 - val_loss: 0.5979\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6470 - val_loss: 0.5870\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5648 - val_loss: 0.5771\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5747 - val_loss: 0.5741\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5588 - val_loss: 0.5719\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5427 - val_loss: 0.5653\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5571 - val_loss: 0.5608\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5656 - val_loss: 0.5577\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5747 - val_loss: 0.5537\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5489 - val_loss: 0.5591\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5494 - val_loss: 0.5509\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5484 - val_loss: 0.5605\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5379 - val_loss: 0.5507\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5604 - val_loss: 0.5466\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5562 - val_loss: 0.5441\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5124 - val_loss: 0.5529\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5395 - val_loss: 0.5500\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5352 - val_loss: 0.5459\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5361 - val_loss: 0.5425\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5270 - val_loss: 0.5563\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5042 - val_loss: 0.5413\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5371 - val_loss: 0.5429\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5234 - val_loss: 0.5412\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5217 - val_loss: 0.5539\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5532 - val_loss: 0.5410\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.5322 - val_loss: 0.5493\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5391 - val_loss: 0.5533\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.5244 - val_loss: 0.5509\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.5762 - val_loss: 0.5402\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.5235 - val_loss: 0.5398\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5269 - val_loss: 0.5465\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5604 - val_loss: 0.5401\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5511 - val_loss: 0.5402\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5436 - val_loss: 0.5499\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5517 - val_loss: 0.5522\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5246 - val_loss: 0.5403\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5368 - val_loss: 0.5396\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5524 - val_loss: 0.5458\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5505 - val_loss: 0.5404\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5244 - val_loss: 0.5468\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5354 - val_loss: 0.5398\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5462 - val_loss: 0.5406\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5323 - val_loss: 0.5402\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5041 - val_loss: 0.5526\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5411 - val_loss: 0.5456\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5604 - val_loss: 0.5415\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5286 - val_loss: 0.5502\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.5285 - val_loss: 0.5401\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5433 - val_loss: 0.5401\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5213 - val_loss: 0.5405\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5487 - val_loss: 0.5408\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5279 - val_loss: 0.5432\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5408 - val_loss: 0.5489\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5919 - val_loss: 0.5418\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5244 - val_loss: 0.5453\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.5395 - val_loss: 0.5441\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5450 - val_loss: 0.5435\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5135 - val_loss: 0.5498\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5322 - val_loss: 0.5411\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5504 - val_loss: 0.5534\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5221 - val_loss: 0.5403\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5341 - val_loss: 0.5481\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5349 - val_loss: 0.5417\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5368 - val_loss: 0.5410\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5645 - val_loss: 0.5433\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5530 - val_loss: 0.5405\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5314 - val_loss: 0.5528\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5730 - val_loss: 0.5536\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.5518 - val_loss: 0.5408\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5585 - val_loss: 0.5408\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.5390 - val_loss: 0.5553\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.5347 - val_loss: 0.5505\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5487 - val_loss: 0.5404\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5263 - val_loss: 0.5400\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5679 - val_loss: 0.5410\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5381 - val_loss: 0.5457\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5290 - val_loss: 0.5412\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5205 - val_loss: 0.5473\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.4963 - val_loss: 0.5401\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5260 - val_loss: 0.5463\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5225 - val_loss: 0.5402\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5336 - val_loss: 0.5402\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5464 - val_loss: 0.5404\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5331 - val_loss: 0.5416\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5286 - val_loss: 0.5490\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5359 - val_loss: 0.5401\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5595 - val_loss: 0.5417\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5167 - val_loss: 0.5434\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5502 - val_loss: 0.5409\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5320 - val_loss: 0.5403\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5496 - val_loss: 0.5416\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5555 - val_loss: 0.5459\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5395 - val_loss: 0.5435\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5553 - val_loss: 0.5403\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5388 - val_loss: 0.5407\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5363 - val_loss: 0.5405\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5171 - val_loss: 0.5408\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5327 - val_loss: 0.5405\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 481us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 804us/step - loss: 4.8312 - val_loss: 1.1183\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.9948 - val_loss: 0.7591\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.7770 - val_loss: 0.7007\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.6620 - val_loss: 0.6715\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6924 - val_loss: 0.6482\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6135 - val_loss: 0.6291\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5979 - val_loss: 0.6144\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.6031 - val_loss: 0.6015\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5912 - val_loss: 0.5910\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.6003 - val_loss: 0.5819\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5781 - val_loss: 0.5759\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5325 - val_loss: 0.5705\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5699 - val_loss: 0.5643\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5462 - val_loss: 0.5610\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5520 - val_loss: 0.5600\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5308 - val_loss: 0.5538\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5433 - val_loss: 0.5521\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5520 - val_loss: 0.5502\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.5335 - val_loss: 0.5521\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5624 - val_loss: 0.5492\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5344 - val_loss: 0.5550\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5573 - val_loss: 0.5441\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5364 - val_loss: 0.5429\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5849 - val_loss: 0.5431\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5435 - val_loss: 0.5482\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5126 - val_loss: 0.5459\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5351 - val_loss: 0.5519\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5288 - val_loss: 0.5408\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5607 - val_loss: 0.5423\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5120 - val_loss: 0.5467\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5309 - val_loss: 0.5402\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.5250 - val_loss: 0.5418\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5274 - val_loss: 0.5399\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 565us/step - loss: 0.5577 - val_loss: 0.5397\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5330 - val_loss: 0.5487\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.5137 - val_loss: 0.5443\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5334 - val_loss: 0.5399\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5125 - val_loss: 0.5397\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5241 - val_loss: 0.5388\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5439 - val_loss: 0.5391\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5358 - val_loss: 0.5515\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5337 - val_loss: 0.5435\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5362 - val_loss: 0.5400\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5370 - val_loss: 0.5497\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5373 - val_loss: 0.5406\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5469 - val_loss: 0.5384\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5354 - val_loss: 0.5442\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5250 - val_loss: 0.5446\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 0.5340 - val_loss: 0.5389\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5244 - val_loss: 0.5403\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5239 - val_loss: 0.5392\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 0.5403 - val_loss: 0.5389\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5523 - val_loss: 0.5394\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5580 - val_loss: 0.5394\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5420 - val_loss: 0.5408\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5376 - val_loss: 0.5406\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5405 - val_loss: 0.5392\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5140 - val_loss: 0.5391\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5382 - val_loss: 0.5402\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5308 - val_loss: 0.5395\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5239 - val_loss: 0.5455\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5137 - val_loss: 0.5399\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.5184 - val_loss: 0.5401\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5390 - val_loss: 0.5407\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5215 - val_loss: 0.5403\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5192 - val_loss: 0.5442\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5347 - val_loss: 0.5404\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5445 - val_loss: 0.5400\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5175 - val_loss: 0.5396\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5398 - val_loss: 0.5456\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5157 - val_loss: 0.5411\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5255 - val_loss: 0.5419\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5106 - val_loss: 0.5397\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.4989 - val_loss: 0.5402\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5332 - val_loss: 0.5406\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5394 - val_loss: 0.5449\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5209 - val_loss: 0.5506\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5339 - val_loss: 0.5410\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5146 - val_loss: 0.5499\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5408 - val_loss: 0.5450\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5354 - val_loss: 0.5401\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5173 - val_loss: 0.5400\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5346 - val_loss: 0.5394\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5437 - val_loss: 0.5479\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5353 - val_loss: 0.5457\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5236 - val_loss: 0.5412\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5368 - val_loss: 0.5400\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5358 - val_loss: 0.5507\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5327 - val_loss: 0.5427\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5562 - val_loss: 0.5445\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5237 - val_loss: 0.5386\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5286 - val_loss: 0.5388\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5213 - val_loss: 0.5436\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.5349 - val_loss: 0.5456\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5354 - val_loss: 0.5396\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5376 - val_loss: 0.5397\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5593 - val_loss: 0.5391\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5327 - val_loss: 0.5389\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5325 - val_loss: 0.5484\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5381 - val_loss: 0.5520\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 822us/step - loss: 2.2228 - val_loss: 1.0706\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 12.4656 - val_loss: 25.8845\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 199.6523 - val_loss: 1149.3059\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 34209.8359 - val_loss: 53242.9023\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 211116.0938 - val_loss: 2483648.7500\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 18416424.0000 - val_loss: 114961080.0000\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 640731136.0000 - val_loss: 5346782208.0000\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 27309285376.0000 - val_loss: 248405622784.0000\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 6196494860288.0000 - val_loss: 11398895632384.0000\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 14407738327040.0000 - val_loss: 586990965751808.0000\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 1570048246284288.0000 - val_loss: 25165091708076032.0000\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 56362056961490944.0000 - val_loss: 1176321036191268864.0000\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 8736591301203460096.0000 - val_loss: 52811663340499632128.0000\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 792121531434570612736.0000 - val_loss: 2443408837531446280192.0000\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 83668792611613058269184.0000 - val_loss: 113215081305342170103808.0000\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 71111883152176405544960.0000 - val_loss: 5804484772035576503205888.0000\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 38343388396554618706853888.0000 - val_loss: 244275843307758098600427520.0000\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 1727604876225280401282695168.0000 - val_loss: 11314158476438586116968284160.0000\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 294694274655008367736772362240.0000 - val_loss: 523097630896494626078795497472.0000\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 14932128259000006431538038177792.0000 - val_loss: 24300924967231843156579219144704.0000\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 133846889445686096352898713649152.0000 - val_loss: 1137329325328801840498583606919168.0000\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 11571011929860017290299090231361536.0000 - val_loss: 52232017840275792900172979856474112.0000\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: inf - val_loss: inf                    \n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: inf - val_loss: inf\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: inf - val_loss: inf\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: inf - val_loss: inf\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: inf - val_loss: inf\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: inf - val_loss: inf\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: inf - val_loss: inf\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: inf - val_loss: inf\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: inf - val_loss: inf\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: inf - val_loss: inf\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: inf - val_loss: inf\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: inf - val_loss: inf\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564us/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: nan - val_loss: nan\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m  1/242\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m24s\u001B[0m 104ms/step - loss: 7.2991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 455, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1127, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1724, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 1204, in r2_score\n",
      "    _, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 113, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 833us/step - loss: 2.6962 - val_loss: 0.6584\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.7397 - val_loss: 0.5994\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5828 - val_loss: 0.5625\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5450 - val_loss: 0.6040\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5604 - val_loss: 0.6349\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5654 - val_loss: 0.5605\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5827 - val_loss: 0.5662\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5300 - val_loss: 0.5411\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5383 - val_loss: 0.7789\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.6260 - val_loss: 1.1075\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.6330 - val_loss: 0.5436\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5430 - val_loss: 1.0303\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 1.2494 - val_loss: 0.6706\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.8927 - val_loss: 0.5439\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5224 - val_loss: 0.8196\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.6152 - val_loss: 0.5455\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5659 - val_loss: 0.5797\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - loss: 1.1995 - val_loss: 0.5554\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5780 - val_loss: 0.5421\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6202 - val_loss: 0.5583\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.6131 - val_loss: 0.5495\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.9332 - val_loss: 0.5440\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.5597 - val_loss: 0.8317\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.8450 - val_loss: 0.5450\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - loss: 0.5294 - val_loss: 0.5735\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5374 - val_loss: 0.6036\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5521 - val_loss: 1.0018\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 0.9523 - val_loss: 0.5678\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5087 - val_loss: 0.6742\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5885 - val_loss: 0.7172\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5723 - val_loss: 0.9383\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 0.7282 - val_loss: 0.5789\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.8931 - val_loss: 0.5502\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5637 - val_loss: 0.6909\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.7743 - val_loss: 1.2151\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 3.0964 - val_loss: 0.6625\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6242 - val_loss: 0.5728\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5516 - val_loss: 0.5626\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5441 - val_loss: 0.5429\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.5993 - val_loss: 0.5507\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.6642 - val_loss: 0.5792\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5405 - val_loss: 0.5418\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.6060 - val_loss: 0.5558\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.6962 - val_loss: 0.5659\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - loss: 0.6638 - val_loss: 0.5844\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5488 - val_loss: 1.8089\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 3.4536 - val_loss: 0.6271\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.7127 - val_loss: 0.5545\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5808 - val_loss: 0.5596\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5415 - val_loss: 1.1211\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.6343 - val_loss: 1.4455\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.6897 - val_loss: 0.5429\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5631 - val_loss: 0.5471\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.6771 - val_loss: 0.5555\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5471 - val_loss: 0.8689\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5823 - val_loss: 1.5908\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 1.0657 - val_loss: 0.7697\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6382 - val_loss: 0.5434\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5229 - val_loss: 0.6495\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5583 - val_loss: 0.7092\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 2.0622 - val_loss: 0.5651\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 1.3457 - val_loss: 0.5496\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5336 - val_loss: 1.0630\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 21.1615 - val_loss: 0.6775\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.7510 - val_loss: 1.7752\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 1.1858 - val_loss: 2.0970\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 3.3400 - val_loss: 0.5449\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5349 - val_loss: 1.8715\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 1.0016 - val_loss: 0.5398\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5275 - val_loss: 0.6371\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5501 - val_loss: 0.5369\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.7079 - val_loss: 0.5399\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5928 - val_loss: 0.5784\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5712 - val_loss: 0.5953\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5823 - val_loss: 0.5368\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5628 - val_loss: 0.7886\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.8671 - val_loss: 1.0635\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 52.4899 - val_loss: 0.8312\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.9744 - val_loss: 0.6200\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5767 - val_loss: 0.5767\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5555 - val_loss: 0.6195\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5863 - val_loss: 0.5680\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5442 - val_loss: 0.5488\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 0.5434 - val_loss: 0.5511\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5321 - val_loss: 0.6461\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5596 - val_loss: 0.5544\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5394 - val_loss: 0.5462\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5411 - val_loss: 0.5424\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 1.1471 - val_loss: 0.5565\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 0.5043 - val_loss: 1.1448\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 1.9240 - val_loss: 0.5969\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - loss: 0.6013 - val_loss: 0.5834\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - loss: 0.5442 - val_loss: 0.5476\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5197 - val_loss: 0.5451\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5304 - val_loss: 0.5537\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5100 - val_loss: 0.5412\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5653 - val_loss: 0.6022\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6146 - val_loss: 5.7242\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - loss: 1.1889 - val_loss: 0.5743\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.7133 - val_loss: 0.5679\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 514us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 820us/step - loss: 2.5807 - val_loss: 0.6138\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.8946 - val_loss: 0.7243\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 11.0982 - val_loss: 0.7184\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 45.2431 - val_loss: 1.4934\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 3.8968 - val_loss: 2.0589\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 362.8528 - val_loss: 11.9264\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 33.3077 - val_loss: 17.5431\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 377.5458 - val_loss: 58.8029\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 555.2537 - val_loss: 163.5494\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 30498.3926 - val_loss: 470.3540\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 30296.0977 - val_loss: 1591.2124\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 1107.4424 - val_loss: 4237.4370\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 32974.2617 - val_loss: 15748.6025\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 882045.7500 - val_loss: 48862.5977\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 1381457.5000 - val_loss: 139820.2812\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 7902099.5000 - val_loss: 472727.3125\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 9177542.0000 - val_loss: 1526105.0000\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 5082031.0000 - val_loss: 2470806.7500\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 34585512.0000 - val_loss: 25919808.0000\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 33966012.0000 - val_loss: 66938152.0000\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 164845872.0000 - val_loss: 59647516.0000\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 2919961600.0000 - val_loss: 195849424.0000\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 3195800832.0000 - val_loss: 466619936.0000\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 1134541312.0000 - val_loss: 1670960256.0000\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 17556717568.0000 - val_loss: 4616255488.0000\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 66886852608.0000 - val_loss: 13024068608.0000\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 330181607424.0000 - val_loss: 48842407936.0000\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 6840218812416.0000 - val_loss: 241748787200.0000\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 852030193664.0000 - val_loss: 436034699264.0000\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 1385577578496.0000 - val_loss: 1254170165248.0000\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 21196745736192.0000 - val_loss: 13857052426240.0000\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 322310519128064.0000 - val_loss: 12439723704320.0000\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 26458099548160.0000 - val_loss: 32767295356928.0000\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 129909313765376.0000 - val_loss: 95134658068480.0000\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 7145351869890560.0000 - val_loss: 274357175713792.0000\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 654631063519232.0000 - val_loss: 1028462802370560.0000\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 8016544109953024.0000 - val_loss: 2196974287716352.0000\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 318602873040535552.0000 - val_loss: 6340657534730240.0000\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 182653259607965696.0000 - val_loss: 36991084441632768.0000\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 156286060240830464.0000 - val_loss: 70338378758881280.0000\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 27000777412039409664.0000 - val_loss: 209882957127614464.0000\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: 605670172048490496.0000 - val_loss: 688107843047391232.0000\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 35479030209959690240.0000 - val_loss: 3169524511116623872.0000\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 268634774368371605504.0000 - val_loss: 7994608419187195904.0000\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 373246339245584416768.0000 - val_loss: 115970733852975955968.0000\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 414912517098109403136.0000 - val_loss: 144083029559766679552.0000\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 459780824654438989824.0000 - val_loss: 411072353990845923328.0000\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 70021003236036214521856.0000 - val_loss: 1253089300881426350080.0000\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 24393760892451173695488.0000 - val_loss: 7048238688476116025344.0000\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 12909456867766749364224.0000 - val_loss: 182251273403662023524352.0000\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 12402531180299568814227456.0000 - val_loss: 489737456294941174005760.0000\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 9184245339752933242175488.0000 - val_loss: 4054724915761756170616832.0000\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 16934134118095460520427520.0000 - val_loss: 4367724081057689111625728.0000\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 373845330959636220121972736.0000 - val_loss: 17583128621018214572228608.0000\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 1730146689984684987818967040.0000 - val_loss: 37035207564608386075983872.0000\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 2198994154876475000689262592.0000 - val_loss: 132267010378008890383007744.0000\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 14418937350182270233277890560.0000 - val_loss: 307469278756178604891045888.0000\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 1575066093148629504794558464.0000 - val_loss: 806065973836336675038429184.0000\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 7399060473757954556561457152.0000 - val_loss: 2334438561580948140209471488.0000\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 282656716927116532865510146048.0000 - val_loss: 8589086792412329052416770048.0000\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 391901600848047401895127416832.0000 - val_loss: 29228329405901168472114593792.0000\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 862545224915146608626920062976.0000 - val_loss: 78244361349621070145465090048.0000\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 476328408839177685640039890944.0000 - val_loss: 173662118429777755032218763264.0000\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 814628090013173714829619232768.0000 - val_loss: 511599461868276162083841638400.0000\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 7128602158361136398683187707904.0000 - val_loss: 1591606300994634129614070349824.0000\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 105344712723684411576155639906304.0000 - val_loss: 4646140687628393807657838837760.0000\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 2078383876398926281102048517685248.0000 - val_loss: 16350071308196906917405038477312.0000\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 201707474121081291231513502810112.0000 - val_loss: 32220822871729727201105873469440.0000\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 3470365591790238654455436002983936.0000 - val_loss: 97657182450974655405299259670528.0000\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 805976259455985439890243883892736.0000 - val_loss: 248411083240695922190098400018432.0000\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 1720556224845952737934716124004352.0000 - val_loss: 695912712730676297046840735432704.0000\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: inf - val_loss: 1978807383973918326584918937698304.0000\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: inf - val_loss: 10843421337350310031389054262575104.0000\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: inf - val_loss: 18731301682928071074005521111449600.0000\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: inf - val_loss: 44571362626848902692394522158039040.0000\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: inf - val_loss: inf\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: inf - val_loss: inf\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: inf - val_loss: inf\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: inf - val_loss: inf\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: inf - val_loss: inf\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: inf - val_loss: inf\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: inf - val_loss: inf\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: inf - val_loss: inf\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: inf - val_loss: inf\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: inf - val_loss: inf\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: inf - val_loss: inf\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: inf - val_loss: inf\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: inf - val_loss: inf\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: inf - val_loss: inf\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: inf - val_loss: inf\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: inf - val_loss: inf\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: inf - val_loss: inf\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: inf - val_loss: inf\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: inf - val_loss: inf\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: inf - val_loss: inf\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: inf - val_loss: inf\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 579us/step - loss: inf - val_loss: inf\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: inf - val_loss: inf\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 475us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 799us/step - loss: 5.9542 - val_loss: 0.8713\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 3.7555 - val_loss: 0.9858\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 4.4443 - val_loss: 1.9274\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 3.1364 - val_loss: 4.1037\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 83.8066 - val_loss: 9.6856\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 115.7363 - val_loss: 24.4845\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 801.8841 - val_loss: 66.2461\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 167.2182 - val_loss: 199.7641\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 3354.6846 - val_loss: 483.4424\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 4585.9482 - val_loss: 1321.4269\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 1955.6637 - val_loss: 4086.1670\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 43398.2266 - val_loss: 9662.9766\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 50809.3750 - val_loss: 27940.9824\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 190319.6250 - val_loss: 72609.9219\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 145052.1719 - val_loss: 218291.5938\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 1382775.8750 - val_loss: 530123.8125\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 3094332.7500 - val_loss: 1456186.8750\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 20448528.0000 - val_loss: 3862360.7500\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 30063704.0000 - val_loss: 10639557.0000\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 287909216.0000 - val_loss: 28050758.0000\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 59298168.0000 - val_loss: 86988792.0000\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 1290086400.0000 - val_loss: 208169552.0000\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 892667520.0000 - val_loss: 592875264.0000\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 3546283776.0000 - val_loss: 1572840576.0000\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 14426435584.0000 - val_loss: 4212577280.0000\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 3632130304.0000 - val_loss: 13329081344.0000\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 55567552512.0000 - val_loss: 32302276608.0000\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 178845368320.0000 - val_loss: 85591908352.0000\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 2413224263680.0000 - val_loss: 224445382656.0000\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 2166304145408.0000 - val_loss: 621481230336.0000\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 17480906964992.0000 - val_loss: 1651681918976.0000\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 75798337814528.0000 - val_loss: 4480763428864.0000\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 15350704898048.0000 - val_loss: 13498059849728.0000\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 161636698554368.0000 - val_loss: 33283647733760.0000\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 32561644437504.0000 - val_loss: 105991311982592.0000\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 2289788530982912.0000 - val_loss: 245216812466176.0000\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 5291722904961024.0000 - val_loss: 669671837663232.0000\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 7225531393114112.0000 - val_loss: 1836612841373696.0000\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 10289700111646720.0000 - val_loss: 5073107458981888.0000\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 62725355953192960.0000 - val_loss: 13502170292813824.0000\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 25535534784839680.0000 - val_loss: 41204236905611264.0000\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 168961453624131584.0000 - val_loss: 101703554258960384.0000\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 1826827711872499712.0000 - val_loss: 266053845094760448.0000\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 2327833241769213952.0000 - val_loss: 731980899616292864.0000\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 8516431140171546624.0000 - val_loss: 1992704983841112064.0000\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 10269009793893007360.0000 - val_loss: 5622991524888313856.0000\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 5578604790230810624.0000 - val_loss: 15936954851682942976.0000\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 285758445314052718592.0000 - val_loss: 38959246195638140928.0000\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 1157802210334265573376.0000 - val_loss: 105719036969173909504.0000\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 3136401919042941616128.0000 - val_loss: 285962285973749366784.0000\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 1185203306735838691328.0000 - val_loss: 841584003192027348992.0000\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 12378578173191849508864.0000 - val_loss: 2115200570437520064512.0000\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 5129513281282168061952.0000 - val_loss: 6440924338075530690560.0000\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 85288377109608036040704.0000 - val_loss: 15627392753683725811712.0000\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 39860252416347926953984.0000 - val_loss: 45437893000851875692544.0000\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 23164620467750708445184.0000 - val_loss: 138863945874345599959040.0000\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 1636576831590625785675776.0000 - val_loss: 313093668830513683496960.0000\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 11321757197608009108291584.0000 - val_loss: 846877194172266763517952.0000\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 9919420725145049105432576.0000 - val_loss: 2323776270872289229144064.0000\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 485596378423175493451776.0000 - val_loss: 7683468970462126823964672.0000\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 53037631227185915349696512.0000 - val_loss: 17380448479272844694388736.0000\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 159292338996220774139822080.0000 - val_loss: 47239270774182810417627136.0000\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 91153396025242995044384768.0000 - val_loss: 141720680791251893088157696.0000\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 828934328677538111338577920.0000 - val_loss: 345147509843237386158342144.0000\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 576us/step - loss: 6326134676779298653070163968.0000 - val_loss: 916695230117045367019143168.0000\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 5219869562727393413075828736.0000 - val_loss: 2580278024703370155243077632.0000\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 24821785348672879391020154880.0000 - val_loss: 6925413608780043087389917184.0000\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 5877551771909217825870315520.0000 - val_loss: 21712990102235514641456300032.0000\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 334108562030983287583843287040.0000 - val_loss: 49920830278288001391826829312.0000\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 1381704288828132361726007967744.0000 - val_loss: 134581239572226397876525203456.0000\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 2462033042232894587231163908096.0000 - val_loss: 369595030529564345763712991232.0000\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 1870568502838076492764516712448.0000 - val_loss: 1054443611544492415187964395520.0000\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 1094400196597894153612795314176.0000 - val_loss: 3176134341315424605410236039168.0000\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step - loss: 51674160819696241854073026904064.0000 - val_loss: 7326240978129194820051677478912.0000\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 78463541111874476933125788139520.0000 - val_loss: 20190242308090070710296827133952.0000\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 252113665184132925421987704078336.0000 - val_loss: 54831212569180504441617819631616.0000\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 397056269230373226681007654043648.0000 - val_loss: 151700151207250029332425158426624.0000\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: 8150351487557145581951266414657536.0000 - val_loss: 395855854248528684495691409522688.0000\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 575us/step - loss: 17559142063510198050773711651340288.0000 - val_loss: 1074871613897989004825365273640960.0000\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 2551921783423904318564202052583424.0000 - val_loss: 3161429608376316651882572708577280.0000\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 18423856798291468311973773812170752.0000 - val_loss: 8127710802178655262103636331724800.0000\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: 21475981871929062669793990897827840.0000\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: inf - val_loss: 58718011557465414331184056964743168.0000\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: inf - val_loss: inf                    \n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: inf - val_loss: inf\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: inf - val_loss: inf\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: inf - val_loss: inf\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 580us/step - loss: inf - val_loss: inf\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: inf - val_loss: inf\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: inf - val_loss: inf\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: inf - val_loss: inf\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: inf - val_loss: inf\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: inf - val_loss: inf\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: inf - val_loss: inf\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: inf - val_loss: inf\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: inf - val_loss: inf\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: inf - val_loss: inf\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: inf - val_loss: inf\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: inf - val_loss: inf\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 442us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 818us/step - loss: 3.9347 - val_loss: 0.6890\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.6566 - val_loss: 0.6134\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5934 - val_loss: 0.5990\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5846 - val_loss: 0.5795\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5529 - val_loss: 0.5700\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5537 - val_loss: 0.5794\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5738 - val_loss: 0.5593\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5712 - val_loss: 0.5610\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5366 - val_loss: 0.5539\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - loss: 0.5396 - val_loss: 0.5988\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5785 - val_loss: 0.5432\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5669 - val_loss: 0.5467\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5322 - val_loss: 0.6053\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5787 - val_loss: 0.5400\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5369 - val_loss: 0.5849\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6028 - val_loss: 0.5949\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5558 - val_loss: 0.5435\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5616 - val_loss: 0.5510\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5418 - val_loss: 0.5588\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5171 - val_loss: 0.6130\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5591 - val_loss: 0.5478\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5370 - val_loss: 0.5706\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5352 - val_loss: 0.5712\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5345 - val_loss: 0.5452\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5769 - val_loss: 0.5508\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.6233 - val_loss: 0.5479\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5723 - val_loss: 0.5520\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5455 - val_loss: 0.5517\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5273 - val_loss: 0.5463\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6026 - val_loss: 0.5477\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5284 - val_loss: 0.5714\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5518 - val_loss: 0.6009\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5392 - val_loss: 0.5485\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.4985 - val_loss: 0.5933\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.9316 - val_loss: 0.5483\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5370 - val_loss: 0.5505\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5252 - val_loss: 0.5615\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5393 - val_loss: 0.5507\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5303 - val_loss: 0.5588\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5364 - val_loss: 0.5671\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5495 - val_loss: 0.5416\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5323 - val_loss: 0.5540\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5450 - val_loss: 0.5709\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.7840 - val_loss: 0.5471\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5540 - val_loss: 0.5645\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5368 - val_loss: 0.5456\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5634 - val_loss: 0.5466\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.5348 - val_loss: 0.5555\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5503 - val_loss: 0.5457\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5356 - val_loss: 0.5569\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5471 - val_loss: 0.5587\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5367 - val_loss: 0.5622\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5422 - val_loss: 0.5480\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5205 - val_loss: 0.5926\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5859 - val_loss: 0.5549\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5428 - val_loss: 0.5492\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5839 - val_loss: 0.5459\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5341 - val_loss: 0.5525\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5408 - val_loss: 0.5662\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5414 - val_loss: 0.5602\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5382 - val_loss: 0.6232\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5608 - val_loss: 0.5470\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5014 - val_loss: 0.5876\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5312 - val_loss: 0.5455\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5090 - val_loss: 0.5867\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5534 - val_loss: 0.5819\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5372 - val_loss: 0.5455\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5222 - val_loss: 0.5915\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5700 - val_loss: 0.5595\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5520 - val_loss: 0.5730\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5238 - val_loss: 0.5489\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5382 - val_loss: 0.5500\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5493 - val_loss: 0.5509\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5544 - val_loss: 0.5613\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5522 - val_loss: 0.5476\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5639 - val_loss: 0.5479\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5593 - val_loss: 0.5583\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.7231 - val_loss: 0.5471\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5912 - val_loss: 0.5477\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5469 - val_loss: 0.5438\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5423 - val_loss: 0.5591\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5211 - val_loss: 0.6075\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.7230 - val_loss: 0.5505\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5484 - val_loss: 0.5966\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5750 - val_loss: 0.5591\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5231 - val_loss: 0.5817\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5570 - val_loss: 0.5643\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5542 - val_loss: 0.5463\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5717 - val_loss: 0.5515\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5287 - val_loss: 0.5701\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5493 - val_loss: 0.5454\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5471 - val_loss: 0.5641\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5341 - val_loss: 0.5430\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5570 - val_loss: 0.5497\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5423 - val_loss: 0.5847\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5449 - val_loss: 0.5413\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5304 - val_loss: 0.5627\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5226 - val_loss: 0.5889\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5644 - val_loss: 0.5767\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5892 - val_loss: 0.5514\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 939us/step - loss: 3.1229 - val_loss: 0.6331\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.6102 - val_loss: 0.5804\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5514 - val_loss: 0.5687\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5450 - val_loss: 0.5610\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5344 - val_loss: 0.5541\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5555 - val_loss: 0.5524\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 0.5267 - val_loss: 0.5488\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5390 - val_loss: 0.5460\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5260 - val_loss: 0.5537\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5342 - val_loss: 0.5590\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5433 - val_loss: 0.5432\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5023 - val_loss: 0.5422\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5312 - val_loss: 0.5488\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5483 - val_loss: 0.5397\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5367 - val_loss: 0.5621\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5277 - val_loss: 0.5387\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5442 - val_loss: 0.5402\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5576 - val_loss: 0.5428\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5182 - val_loss: 0.5704\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5484 - val_loss: 0.5566\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5294 - val_loss: 0.5390\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5276 - val_loss: 0.5455\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.5379 - val_loss: 0.6002\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.5682 - val_loss: 0.5415\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5246 - val_loss: 0.5393\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5251 - val_loss: 0.5389\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5531 - val_loss: 0.5505\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5172 - val_loss: 0.5424\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - loss: 0.5342 - val_loss: 0.5404\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5180 - val_loss: 0.5474\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.4995 - val_loss: 0.5386\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5298 - val_loss: 0.5682\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5399 - val_loss: 0.5387\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5274 - val_loss: 0.5433\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5153 - val_loss: 0.5387\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5821 - val_loss: 0.5391\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5245 - val_loss: 0.5393\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5373 - val_loss: 0.5389\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5381 - val_loss: 0.5487\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5326 - val_loss: 0.5407\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5489 - val_loss: 0.5399\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5459 - val_loss: 0.5420\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5437 - val_loss: 0.5403\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5883 - val_loss: 0.5383\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5499 - val_loss: 0.5430\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5438 - val_loss: 0.5431\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5157 - val_loss: 0.5397\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.4924 - val_loss: 0.5643\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5552 - val_loss: 0.5400\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5646 - val_loss: 0.5383\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5231 - val_loss: 0.5386\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5254 - val_loss: 0.5421\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5409 - val_loss: 0.5388\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5705 - val_loss: 0.5398\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5540 - val_loss: 0.5453\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5322 - val_loss: 0.5409\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5352 - val_loss: 0.5443\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5503 - val_loss: 0.5411\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5342 - val_loss: 0.5460\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5201 - val_loss: 0.5684\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.5509 - val_loss: 0.5422\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5547 - val_loss: 0.5390\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5782 - val_loss: 0.5405\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5560 - val_loss: 0.5388\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5497 - val_loss: 0.5681\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 645us/step - loss: 0.5400 - val_loss: 0.5407\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5390 - val_loss: 0.5799\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5295 - val_loss: 0.5387\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5480 - val_loss: 0.5408\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5211 - val_loss: 0.5384\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5661 - val_loss: 0.5402\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5508 - val_loss: 0.5521\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5413 - val_loss: 0.5699\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5399 - val_loss: 0.5400\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.5283 - val_loss: 0.5509\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5326 - val_loss: 0.5392\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5300 - val_loss: 0.6028\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5642 - val_loss: 0.5469\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5198 - val_loss: 0.5399\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5406 - val_loss: 0.5571\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5350 - val_loss: 0.5722\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.5343 - val_loss: 0.5389\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5655 - val_loss: 0.5388\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5325 - val_loss: 0.5494\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5491 - val_loss: 0.5682\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5537 - val_loss: 0.5682\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.5529 - val_loss: 0.5452\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5453 - val_loss: 0.5386\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5709 - val_loss: 0.5409\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5197 - val_loss: 0.5705\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5326 - val_loss: 0.5672\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5257 - val_loss: 0.5460\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5530 - val_loss: 0.5518\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5247 - val_loss: 0.5560\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5274 - val_loss: 0.5676\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5233 - val_loss: 0.6030\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.5410 - val_loss: 0.5403\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5312 - val_loss: 0.5404\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5265 - val_loss: 0.5398\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5519 - val_loss: 0.5401\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 475us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 901us/step - loss: 3.7938 - val_loss: 0.5797\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.5277 - val_loss: 0.5066\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4858 - val_loss: 0.4827\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4484 - val_loss: 0.4674\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4521 - val_loss: 0.4698\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4208 - val_loss: 0.4560\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4198 - val_loss: 0.4673\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4756 - val_loss: 0.4643\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.4319 - val_loss: 0.4928\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4296 - val_loss: 0.4641\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4205 - val_loss: 0.4466\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4152 - val_loss: 0.4558\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4729 - val_loss: 0.4434\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4346 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.4275 - val_loss: 0.4521\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 0.4923 - val_loss: 0.4647\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.4380 - val_loss: 0.4622\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4422 - val_loss: 0.4518\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.4393 - val_loss: 0.4678\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.4305 - val_loss: 0.4503\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4453 - val_loss: 0.4526\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4429 - val_loss: 0.4575\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4283 - val_loss: 0.4476\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4187 - val_loss: 0.4521\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.4345 - val_loss: 0.4504\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.4232 - val_loss: 0.4581\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4509 - val_loss: 0.4561\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.4265 - val_loss: 0.4561\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.4445 - val_loss: 0.4879\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4333 - val_loss: 0.4611\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.4410 - val_loss: 0.4628\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4396 - val_loss: 0.4471\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4908 - val_loss: 0.4477\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4374 - val_loss: 0.4503\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.4582 - val_loss: 0.4499\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4573 - val_loss: 0.5211\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4919 - val_loss: 0.4678\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4577 - val_loss: 0.4505\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4243 - val_loss: 0.4552\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4016 - val_loss: 0.4468\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4220 - val_loss: 0.4465\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4214 - val_loss: 0.4488\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.4668 - val_loss: 0.4500\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4170 - val_loss: 0.4444\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4364 - val_loss: 0.4570\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4528 - val_loss: 0.4458\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4446 - val_loss: 0.4494\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4671 - val_loss: 0.5068\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4747 - val_loss: 0.4635\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4541 - val_loss: 0.4572\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4466 - val_loss: 0.4490\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.4252 - val_loss: 0.4510\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4216 - val_loss: 0.4479\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.4273 - val_loss: 0.4454\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4435 - val_loss: 0.4444\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4333 - val_loss: 0.4638\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4452 - val_loss: 0.4485\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4124 - val_loss: 0.4490\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4303 - val_loss: 0.4580\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4285 - val_loss: 0.4524\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4447 - val_loss: 0.4466\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4244 - val_loss: 0.4485\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4315 - val_loss: 0.4569\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4245 - val_loss: 0.4540\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.4736 - val_loss: 0.5311\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4840 - val_loss: 0.4848\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4524 - val_loss: 0.4647\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4516 - val_loss: 0.4476\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4256 - val_loss: 0.4474\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4105 - val_loss: 0.4496\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4256 - val_loss: 0.4527\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4333 - val_loss: 0.4504\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4143 - val_loss: 0.4458\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4586 - val_loss: 0.4455\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.4422 - val_loss: 0.4450\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 0.4414 - val_loss: 0.4501\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4320 - val_loss: 0.4494\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.4121 - val_loss: 0.5454\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.5083 - val_loss: 0.4478\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.4371 - val_loss: 0.4449\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4424 - val_loss: 0.4444\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4306 - val_loss: 0.4477\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.4400 - val_loss: 0.5914\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.4633 - val_loss: 0.4457\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4369 - val_loss: 0.4512\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4345 - val_loss: 0.4500\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4383 - val_loss: 0.4983\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4447 - val_loss: 0.4455\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.4420 - val_loss: 0.4466\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4218 - val_loss: 0.4445\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4333 - val_loss: 0.4474\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4184 - val_loss: 0.4479\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.4219 - val_loss: 0.4766\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4309 - val_loss: 0.4555\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4379 - val_loss: 0.4738\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4330 - val_loss: 0.4522\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.4268 - val_loss: 0.4469\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4139 - val_loss: 0.4436\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.4342 - val_loss: 0.4832\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.4174 - val_loss: 0.4460\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 856us/step - loss: 1.7299 - val_loss: 0.5596\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5451 - val_loss: 0.5095\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4932 - val_loss: 0.4913\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4831 - val_loss: 0.4925\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.4732 - val_loss: 0.4876\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 0.4916 - val_loss: 0.4807\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.4778 - val_loss: 0.4743\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.4587 - val_loss: 0.4692\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.4504 - val_loss: 0.4860\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4717 - val_loss: 0.4652\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.4541 - val_loss: 0.4629\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.4545 - val_loss: 0.4600\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4454 - val_loss: 0.4488\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.4490 - val_loss: 0.4469\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.4286 - val_loss: 0.4433\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5196 - val_loss: 0.4680\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4449 - val_loss: 0.4488\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4394 - val_loss: 0.4421\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4428 - val_loss: 0.4368\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 0.4175 - val_loss: 0.4352\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 0.4257 - val_loss: 0.4492\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4183 - val_loss: 0.4372\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4229 - val_loss: 0.4418\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4425 - val_loss: 0.4321\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.4061 - val_loss: 0.4268\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5712 - val_loss: 0.5606\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5238 - val_loss: 0.5265\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5109 - val_loss: 0.5107\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4856 - val_loss: 0.5015\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.4773 - val_loss: 0.4976\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4765 - val_loss: 0.4986\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.4826 - val_loss: 0.4923\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4680 - val_loss: 0.4888\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4693 - val_loss: 0.4843\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4523 - val_loss: 0.4779\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4416 - val_loss: 0.4808\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4692 - val_loss: 0.4735\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.4525 - val_loss: 0.4644\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.4365 - val_loss: 0.4645\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4588 - val_loss: 0.4536\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4310 - val_loss: 0.4472\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4314 - val_loss: 0.4408\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.4205 - val_loss: 0.4328\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.4151 - val_loss: 0.4239\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3941 - val_loss: 0.4195\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.4200 - val_loss: 0.4202\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4315 - val_loss: 0.4080\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - loss: 0.4010 - val_loss: 0.4073\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 0.3938 - val_loss: 0.4092\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.3831 - val_loss: 0.4063\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3974 - val_loss: 0.4032\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4045 - val_loss: 0.4325\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4221 - val_loss: 0.4038\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.4079 - val_loss: 0.4070\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4045 - val_loss: 0.3964\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3845 - val_loss: 0.4825\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.4324 - val_loss: 0.4356\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3958 - val_loss: 0.4179\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.4305 - val_loss: 0.4051\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4079 - val_loss: 0.3974\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4122 - val_loss: 0.4034\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.3932 - val_loss: 0.3976\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3849 - val_loss: 0.5202\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4568 - val_loss: 0.4381\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.4215 - val_loss: 0.4169\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.4285 - val_loss: 0.4037\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.4013 - val_loss: 0.3952\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3841 - val_loss: 0.4457\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4189 - val_loss: 0.4151\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4134 - val_loss: 0.4041\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4047 - val_loss: 0.3946\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.4028 - val_loss: 0.4316\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.4290 - val_loss: 0.4139\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4028 - val_loss: 0.4029\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3923 - val_loss: 0.3974\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3962 - val_loss: 0.3952\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3936 - val_loss: 0.4131\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4157 - val_loss: 0.3931\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3770 - val_loss: 0.3938\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4080 - val_loss: 0.4196\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4134 - val_loss: 0.4011\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3870 - val_loss: 0.4409\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4133 - val_loss: 0.3991\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3948 - val_loss: 0.3966\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3821 - val_loss: 0.3962\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3884 - val_loss: 0.4054\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4061 - val_loss: 0.3983\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3945 - val_loss: 0.4020\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3776 - val_loss: 0.4264\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4039 - val_loss: 0.4155\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3901 - val_loss: 0.3990\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3969 - val_loss: 0.4007\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3986 - val_loss: 0.4210\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3951 - val_loss: 0.3969\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4047 - val_loss: 0.3961\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3732 - val_loss: 0.3915\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3773 - val_loss: 0.3913\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3753 - val_loss: 0.3867\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3821 - val_loss: 0.3900\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3867 - val_loss: 0.4008\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 873us/step - loss: 1.4726 - val_loss: 0.5624\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.5445 - val_loss: 0.5093\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4697 - val_loss: 0.4891\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4816 - val_loss: 0.4898\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4922 - val_loss: 0.4814\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4810 - val_loss: 0.4713\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4689 - val_loss: 0.4684\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4684 - val_loss: 0.4685\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4862 - val_loss: 0.4565\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.4525 - val_loss: 0.4969\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4658 - val_loss: 0.4661\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4372 - val_loss: 0.4485\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4248 - val_loss: 0.4482\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4547 - val_loss: 0.4546\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.4378 - val_loss: 0.4420\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4117 - val_loss: 0.4479\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4368 - val_loss: 0.4312\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4115 - val_loss: 0.4413\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.4134 - val_loss: 0.4311\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4059 - val_loss: 0.4272\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4259 - val_loss: 0.4280\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.4990 - val_loss: 0.4548\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4689 - val_loss: 0.4369\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4367 - val_loss: 0.4628\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4419 - val_loss: 0.4405\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4195 - val_loss: 0.4341\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.4548 - val_loss: 0.4590\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4356 - val_loss: 0.4368\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4283 - val_loss: 0.4317\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3874 - val_loss: 0.4139\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4007 - val_loss: 0.4212\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.4056 - val_loss: 0.4533\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.4339 - val_loss: 0.4104\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.3921 - val_loss: 0.4262\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.4191 - val_loss: 0.4106\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4046 - val_loss: 0.4156\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.4181 - val_loss: 0.4174\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4060 - val_loss: 0.4141\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.4083 - val_loss: 0.4093\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.4152 - val_loss: 0.4220\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.3975 - val_loss: 0.4064\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.4095 - val_loss: 0.4513\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4182 - val_loss: 0.4277\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.4008 - val_loss: 0.4169\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.4036 - val_loss: 0.4209\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.4159 - val_loss: 0.4108\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4052 - val_loss: 0.4194\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3867 - val_loss: 0.4142\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.3953 - val_loss: 0.4083\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3896 - val_loss: 0.4047\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4013 - val_loss: 0.4381\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.4024 - val_loss: 0.4176\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3820 - val_loss: 0.4114\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3944 - val_loss: 0.4076\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - loss: 0.4149 - val_loss: 0.4061\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3999 - val_loss: 0.4258\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.3947 - val_loss: 0.4057\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.4001 - val_loss: 0.4094\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3949 - val_loss: 0.4097\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4034 - val_loss: 0.4050\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.4181 - val_loss: 0.4045\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3947 - val_loss: 0.4109\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3913 - val_loss: 0.4280\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3941 - val_loss: 0.4230\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.4146 - val_loss: 0.4150\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.3962 - val_loss: 0.4043\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.3717 - val_loss: 0.4082\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3954 - val_loss: 0.4119\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 0.3948 - val_loss: 0.4071\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.3889 - val_loss: 0.4050\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - loss: 0.3726 - val_loss: 0.4146\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3956 - val_loss: 0.4049\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3956 - val_loss: 0.4051\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - loss: 0.3974 - val_loss: 0.4145\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4123 - val_loss: 0.4093\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.4051 - val_loss: 0.4052\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3961 - val_loss: 0.4150\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3870 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3963 - val_loss: 0.4238\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.4121 - val_loss: 0.4089\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3945 - val_loss: 0.4049\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.3885 - val_loss: 0.4011\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3878 - val_loss: 0.4030\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3882 - val_loss: 0.4024\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4022 - val_loss: 0.4132\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3946 - val_loss: 0.4039\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3830 - val_loss: 0.4170\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.4004 - val_loss: 0.4074\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3860 - val_loss: 0.4057\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3890 - val_loss: 0.4016\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.3870 - val_loss: 0.4052\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3954 - val_loss: 0.4103\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3984 - val_loss: 0.4036\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3748 - val_loss: 0.4044\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3818 - val_loss: 0.4000\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3834 - val_loss: 0.4102\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3965 - val_loss: 0.4024\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3911 - val_loss: 0.4027\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4082 - val_loss: 0.4107\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3750 - val_loss: 0.4050\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 882us/step - loss: 1.7287 - val_loss: 2.4067\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 8.7465 - val_loss: 0.5011\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5225 - val_loss: 0.4809\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.6651 - val_loss: 0.4197\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3845 - val_loss: 0.4080\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3559 - val_loss: 0.4036\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3820 - val_loss: 0.3938\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3836 - val_loss: 0.3869\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3565 - val_loss: 0.3838\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.3788 - val_loss: 0.3821\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3444 - val_loss: 0.3882\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3673 - val_loss: 0.3823\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3658 - val_loss: 0.3778\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3599 - val_loss: 0.3767\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3497 - val_loss: 0.3798\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3452 - val_loss: 0.3732\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3625 - val_loss: 0.3929\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3670 - val_loss: 0.3897\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3606 - val_loss: 0.3660\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3470 - val_loss: 0.3661\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3518 - val_loss: 0.3700\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3470 - val_loss: 0.3646\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3545 - val_loss: 0.3621\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3502 - val_loss: 0.3662\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3725 - val_loss: 0.3622\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3422 - val_loss: 0.3598\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.3605 - val_loss: 0.3644\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3327 - val_loss: 0.3691\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3358 - val_loss: 0.3623\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.4001 - val_loss: 0.3658\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3569 - val_loss: 0.3741\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3434 - val_loss: 0.3560\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3416 - val_loss: 0.3875\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3355 - val_loss: 0.3563\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3342 - val_loss: 0.3549\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3308 - val_loss: 0.3572\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3347 - val_loss: 0.3596\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.3426 - val_loss: 0.3543\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3409 - val_loss: 0.3741\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3348 - val_loss: 0.3560\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3385 - val_loss: 0.3637\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.3499 - val_loss: 0.4142\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3455 - val_loss: 0.3560\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3333 - val_loss: 0.3574\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.3421 - val_loss: 0.3523\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3243 - val_loss: 0.3517\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3357 - val_loss: 0.3521\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.3401 - val_loss: 0.3516\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3415 - val_loss: 0.3507\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3362 - val_loss: 0.3533\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3356 - val_loss: 0.3467\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 655us/step - loss: 0.3241 - val_loss: 0.3508\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3087 - val_loss: 0.3489\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3353 - val_loss: 0.3561\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3328 - val_loss: 0.3493\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3156 - val_loss: 0.3445\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3125 - val_loss: 0.3429\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3287 - val_loss: 0.3536\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3675 - val_loss: 0.3539\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3814 - val_loss: 0.3504\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3288 - val_loss: 0.3457\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3356 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3069 - val_loss: 0.3449\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3272 - val_loss: 0.3424\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.2983 - val_loss: 0.3412\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.3332 - val_loss: 0.3421\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3107 - val_loss: 0.3442\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3388 - val_loss: 0.3380\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.3176 - val_loss: 0.3430\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3130 - val_loss: 0.3491\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.3215 - val_loss: 0.3373\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3040 - val_loss: 0.3367\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3023 - val_loss: 0.3425\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3058 - val_loss: 0.3457\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.2995 - val_loss: 0.3498\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 0.3193 - val_loss: 0.3387\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3079 - val_loss: 0.3342\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.2990 - val_loss: 0.3379\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3382 - val_loss: 0.3380\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3079 - val_loss: 0.3413\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3184 - val_loss: 0.3375\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3000 - val_loss: 0.3351\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3175 - val_loss: 0.3501\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3169 - val_loss: 0.3409\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.3226 - val_loss: 0.3474\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3048 - val_loss: 0.3374\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3007 - val_loss: 0.3376\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3277 - val_loss: 0.3360\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3220 - val_loss: 0.3345\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3094 - val_loss: 0.3325\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3184 - val_loss: 0.3350\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.3027 - val_loss: 0.3305\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.2920 - val_loss: 0.3366\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3025 - val_loss: 0.3327\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3116 - val_loss: 0.3318\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3236 - val_loss: 0.3310\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.3051 - val_loss: 0.3322\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.2989 - val_loss: 0.3791\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3091 - val_loss: 0.3380\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3240 - val_loss: 0.3286\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 508us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 863us/step - loss: 1.7430 - val_loss: 0.6676\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.6133 - val_loss: 0.5829\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.5687 - val_loss: 0.7500\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5480 - val_loss: 0.5081\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5242 - val_loss: 0.4907\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.4727 - val_loss: 0.5089\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.5018 - val_loss: 0.4898\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4956 - val_loss: 0.4708\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4766 - val_loss: 0.4719\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4627 - val_loss: 0.4602\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4432 - val_loss: 0.4569\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4469 - val_loss: 0.4512\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 0.4696 - val_loss: 0.4533\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 0.4374 - val_loss: 0.4486\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4183 - val_loss: 0.4441\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4439 - val_loss: 0.4538\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4400 - val_loss: 0.4381\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.4204 - val_loss: 0.4416\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4751 - val_loss: 0.4387\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4571 - val_loss: 0.4282\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4117 - val_loss: 0.4268\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4191 - val_loss: 0.4246\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.4050 - val_loss: 0.4239\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.4300 - val_loss: 0.4272\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4239 - val_loss: 0.4180\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3909 - val_loss: 0.4195\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 0.3859 - val_loss: 0.4132\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.4019 - val_loss: 0.4123\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.3897 - val_loss: 0.4085\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3838 - val_loss: 0.4069\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.3837 - val_loss: 0.4067\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3890 - val_loss: 0.4040\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3865 - val_loss: 0.4024\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3684 - val_loss: 0.4006\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - loss: 0.4152 - val_loss: 0.3967\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3850 - val_loss: 0.4013\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3822 - val_loss: 0.3980\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3858 - val_loss: 0.3921\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3888 - val_loss: 0.3921\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3849 - val_loss: 0.3925\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.4058 - val_loss: 0.3900\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.3773 - val_loss: 0.3898\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3717 - val_loss: 0.3879\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3531 - val_loss: 0.3978\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3747 - val_loss: 0.3878\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3798 - val_loss: 0.3847\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3759 - val_loss: 0.5548\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.5662 - val_loss: 0.4223\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4117 - val_loss: 0.4017\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3742 - val_loss: 0.3876\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3878 - val_loss: 0.3870\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 649us/step - loss: 0.3671 - val_loss: 0.3826\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.3657 - val_loss: 0.3811\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3641 - val_loss: 0.3774\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3540 - val_loss: 0.3776\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3619 - val_loss: 0.3801\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.3744 - val_loss: 0.3810\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3797 - val_loss: 0.3779\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.3711 - val_loss: 0.3732\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3657 - val_loss: 0.3701\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3707 - val_loss: 0.3686\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3492 - val_loss: 0.3687\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3621 - val_loss: 0.3709\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3590 - val_loss: 0.3734\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.3724 - val_loss: 0.3698\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3671 - val_loss: 0.3656\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 0.3380 - val_loss: 0.3640\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3430 - val_loss: 0.3657\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3629 - val_loss: 0.3613\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.3368 - val_loss: 0.3645\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 0.3485 - val_loss: 0.3639\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3455 - val_loss: 0.3619\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.3423 - val_loss: 0.3612\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3369 - val_loss: 0.3572\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3277 - val_loss: 0.3583\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3452 - val_loss: 0.3608\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3459 - val_loss: 0.3553\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 0.3529 - val_loss: 0.3548\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3491 - val_loss: 0.3541\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.3465 - val_loss: 0.3538\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3543 - val_loss: 0.3531\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3655 - val_loss: 0.3916\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3645 - val_loss: 0.3602\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3959 - val_loss: 0.3692\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3431 - val_loss: 0.3609\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3508 - val_loss: 0.3640\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3777 - val_loss: 0.3708\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3575 - val_loss: 0.3565\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3502 - val_loss: 0.3516\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3462 - val_loss: 0.3497\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.3387 - val_loss: 0.3521\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3609 - val_loss: 0.3502\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3524 - val_loss: 0.3460\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3243 - val_loss: 0.3443\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3231 - val_loss: 0.3457\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3200 - val_loss: 0.3459\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3375 - val_loss: 0.3453\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3325 - val_loss: 0.3456\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - loss: 0.3255 - val_loss: 0.3509\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 644us/step - loss: 0.3629 - val_loss: 0.3442\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 913us/step - loss: 1.5921 - val_loss: 0.6519\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 1.7534 - val_loss: 0.5548\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.5694 - val_loss: 0.4990\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.4866 - val_loss: 0.4847\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.4797 - val_loss: 0.4718\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4667 - val_loss: 0.4593\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4650 - val_loss: 0.4561\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.4522 - val_loss: 0.4467\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.4389 - val_loss: 0.4414\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 626us/step - loss: 0.4207 - val_loss: 0.4353\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.4391 - val_loss: 0.4337\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.4120 - val_loss: 0.4294\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.4214 - val_loss: 0.4258\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.4171 - val_loss: 0.4225\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.4388 - val_loss: 0.4186\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.4188 - val_loss: 0.4156\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.4159 - val_loss: 0.4133\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.4009 - val_loss: 0.4123\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.3979 - val_loss: 0.4117\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3920 - val_loss: 0.4051\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3884 - val_loss: 0.4046\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.4023 - val_loss: 0.4044\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.3902 - val_loss: 0.4018\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3950 - val_loss: 0.4004\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3844 - val_loss: 0.3978\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3751 - val_loss: 0.3984\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3660 - val_loss: 0.3957\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - loss: 0.3908 - val_loss: 0.3907\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.4033 - val_loss: 0.3886\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3886 - val_loss: 0.3910\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3641 - val_loss: 0.3865\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3700 - val_loss: 0.3848\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.3590 - val_loss: 0.3840\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3693 - val_loss: 0.3815\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3533 - val_loss: 0.3794\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3750 - val_loss: 0.3796\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3666 - val_loss: 0.3834\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3508 - val_loss: 0.3899\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 1.0679 - val_loss: 0.3792\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3849 - val_loss: 0.3793\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.3647 - val_loss: 0.3778\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3582 - val_loss: 0.3804\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3432 - val_loss: 0.3749\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.3659 - val_loss: 0.3723\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step - loss: 0.3624 - val_loss: 0.3738\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - loss: 0.3795 - val_loss: 0.3720\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3711 - val_loss: 0.3687\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.3466 - val_loss: 0.3673\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3468 - val_loss: 0.3669\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 640us/step - loss: 0.3414 - val_loss: 0.3630\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.3522 - val_loss: 0.3624\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3607 - val_loss: 0.3651\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3337 - val_loss: 0.3646\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3579 - val_loss: 0.3614\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.3570 - val_loss: 0.3612\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3485 - val_loss: 0.3604\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3386 - val_loss: 0.3560\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3544 - val_loss: 0.3561\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.3566 - val_loss: 0.3604\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3291 - val_loss: 0.3558\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3370 - val_loss: 0.3584\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3385 - val_loss: 0.3554\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3271 - val_loss: 0.3552\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3327 - val_loss: 0.3541\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3398 - val_loss: 0.3527\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 652us/step - loss: 0.3441 - val_loss: 0.3527\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 631us/step - loss: 0.3330 - val_loss: 0.3510\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3319 - val_loss: 0.3492\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.3422 - val_loss: 0.3514\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3262 - val_loss: 0.3470\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3543 - val_loss: 0.3511\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 0.3215 - val_loss: 0.3563\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3327 - val_loss: 0.3454\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3152 - val_loss: 0.3457\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 0.3369 - val_loss: 0.3471\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3199 - val_loss: 0.3448\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3206 - val_loss: 0.3431\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3154 - val_loss: 0.3457\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3210 - val_loss: 0.3477\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 0.3206 - val_loss: 0.3546\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 0.3094 - val_loss: 0.3473\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 0.3278 - val_loss: 0.3413\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 0.3295 - val_loss: 0.3422\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3426 - val_loss: 0.3399\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3270 - val_loss: 0.6862\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 632us/step - loss: 0.3651 - val_loss: 0.3383\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 0.3182 - val_loss: 0.3394\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 629us/step - loss: 0.3289 - val_loss: 0.3394\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3281 - val_loss: 0.3413\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3105 - val_loss: 0.3370\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 639us/step - loss: 0.3349 - val_loss: 0.3447\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.3480 - val_loss: 0.3372\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 0.3076 - val_loss: 0.3390\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.3082 - val_loss: 0.3437\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 0.3337 - val_loss: 0.3362\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 0.3142 - val_loss: 0.3363\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3251 - val_loss: 0.3655\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3177 - val_loss: 0.3395\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step - loss: 0.3153 - val_loss: 0.3380\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 635us/step - loss: 0.3266 - val_loss: 0.3360\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 838us/step - loss: 10.0400 - val_loss: 6.5494\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 6.0099 - val_loss: 4.7770\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 4.2751 - val_loss: 3.5664\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 3.2290 - val_loss: 2.7287\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 2.3583 - val_loss: 2.1422\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 2.0247 - val_loss: 1.7275\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 1.6238 - val_loss: 1.4319\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 1.3556 - val_loss: 1.2190\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 1.1692 - val_loss: 1.0645\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.9666 - val_loss: 0.9515\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.8701 - val_loss: 0.8684\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.7957 - val_loss: 0.8068\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.7476 - val_loss: 0.7609\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.7127 - val_loss: 0.7265\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.7177 - val_loss: 0.7005\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.6673 - val_loss: 0.6807\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6548 - val_loss: 0.6655\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6514 - val_loss: 0.6536\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6404 - val_loss: 0.6443\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.6186 - val_loss: 0.6369\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.6080 - val_loss: 0.6309\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.6091 - val_loss: 0.6259\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6347 - val_loss: 0.6218\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5919 - val_loss: 0.6183\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5829 - val_loss: 0.6152\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.6057 - val_loss: 0.6126\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 630us/step - loss: 0.6034 - val_loss: 0.6102\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5793 - val_loss: 0.6080\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 625us/step - loss: 0.5732 - val_loss: 0.6061\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5538 - val_loss: 0.6042\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5902 - val_loss: 0.6025\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5873 - val_loss: 0.6009\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5846 - val_loss: 0.5994\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5658 - val_loss: 0.5979\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5720 - val_loss: 0.5965\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5516 - val_loss: 0.5951\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5750 - val_loss: 0.5938\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5861 - val_loss: 0.5925\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5703 - val_loss: 0.5913\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 0.5692 - val_loss: 0.5901\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.5471 - val_loss: 0.5889\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5571 - val_loss: 0.5878\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5439 - val_loss: 0.5867\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5453 - val_loss: 0.5856\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5668 - val_loss: 0.5846\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5518 - val_loss: 0.5835\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5789 - val_loss: 0.5825\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5530 - val_loss: 0.5815\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5995 - val_loss: 0.5806\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5352 - val_loss: 0.5796\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5540 - val_loss: 0.5787\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5212 - val_loss: 0.5778\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.5571 - val_loss: 0.5769\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5466 - val_loss: 0.5761\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 0.5464 - val_loss: 0.5752\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5656 - val_loss: 0.5744\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5644 - val_loss: 0.5737\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5505 - val_loss: 0.5729\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5141 - val_loss: 0.5721\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5599 - val_loss: 0.5714\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5486 - val_loss: 0.5706\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5352 - val_loss: 0.5699\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5698 - val_loss: 0.5692\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5550 - val_loss: 0.5685\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5568 - val_loss: 0.5678\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5536 - val_loss: 0.5672\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5404 - val_loss: 0.5665\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5486 - val_loss: 0.5659\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5593 - val_loss: 0.5653\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5706 - val_loss: 0.5647\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5383 - val_loss: 0.5641\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5470 - val_loss: 0.5636\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5204 - val_loss: 0.5630\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5429 - val_loss: 0.5625\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - loss: 0.5243 - val_loss: 0.5619\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 622us/step - loss: 0.5679 - val_loss: 0.5614\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5329 - val_loss: 0.5609\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5153 - val_loss: 0.5604\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5404 - val_loss: 0.5599\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5444 - val_loss: 0.5594\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5508 - val_loss: 0.5589\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5265 - val_loss: 0.5585\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5354 - val_loss: 0.5581\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5174 - val_loss: 0.5577\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.5562 - val_loss: 0.5572\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5382 - val_loss: 0.5568\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5417 - val_loss: 0.5564\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step - loss: 0.5485 - val_loss: 0.5560\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5154 - val_loss: 0.5556\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5523 - val_loss: 0.5552\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5363 - val_loss: 0.5548\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5318 - val_loss: 0.5544\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5437 - val_loss: 0.5541\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5262 - val_loss: 0.5537\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5209 - val_loss: 0.5534\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5177 - val_loss: 0.5530\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5296 - val_loss: 0.5527\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.5153 - val_loss: 0.5523\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5586 - val_loss: 0.5520\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5599 - val_loss: 0.5517\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 450us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 823us/step - loss: 7.7430 - val_loss: 6.1289\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 5.9024 - val_loss: 4.6046\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 4.3542 - val_loss: 3.5155\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 3.3306 - val_loss: 2.7325\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 2.6071 - val_loss: 2.1661\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 2.0322 - val_loss: 1.7554\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 1.6551 - val_loss: 1.4561\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 1.3567 - val_loss: 1.2371\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 1.1842 - val_loss: 1.0769\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 1.0508 - val_loss: 0.9593\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.9509 - val_loss: 0.8725\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.8863 - val_loss: 0.8084\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.8032 - val_loss: 0.7608\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.7529 - val_loss: 0.7253\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.7138 - val_loss: 0.6987\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6735 - val_loss: 0.6786\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6502 - val_loss: 0.6634\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.6647 - val_loss: 0.6518\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6421 - val_loss: 0.6428\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.6602 - val_loss: 0.6358\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.6429 - val_loss: 0.6302\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.6235 - val_loss: 0.6257\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.6239 - val_loss: 0.6220\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.6653 - val_loss: 0.6189\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5985 - val_loss: 0.6163\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5780 - val_loss: 0.6140\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.6510 - val_loss: 0.6120\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5981 - val_loss: 0.6102\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6101 - val_loss: 0.6085\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6453 - val_loss: 0.6070\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6000 - val_loss: 0.6055\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5974 - val_loss: 0.6041\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.6098 - val_loss: 0.6028\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5880 - val_loss: 0.6016\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5880 - val_loss: 0.6004\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.6161 - val_loss: 0.5992\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5848 - val_loss: 0.5981\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.6006 - val_loss: 0.5970\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 0.6002 - val_loss: 0.5959\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5950 - val_loss: 0.5948\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5839 - val_loss: 0.5938\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5984 - val_loss: 0.5928\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5723 - val_loss: 0.5918\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.6097 - val_loss: 0.5908\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5980 - val_loss: 0.5899\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5984 - val_loss: 0.5890\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5978 - val_loss: 0.5881\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5892 - val_loss: 0.5871\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5940 - val_loss: 0.5863\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6079 - val_loss: 0.5854\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5743 - val_loss: 0.5845\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5848 - val_loss: 0.5837\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 624us/step - loss: 0.6027 - val_loss: 0.5829\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5733 - val_loss: 0.5821\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5720 - val_loss: 0.5813\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5659 - val_loss: 0.5805\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 617us/step - loss: 0.5693 - val_loss: 0.5797\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6092 - val_loss: 0.5790\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.5788 - val_loss: 0.5782\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5834 - val_loss: 0.5775\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 0.6095 - val_loss: 0.5768\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.5478 - val_loss: 0.5761\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5743 - val_loss: 0.5754\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.5556 - val_loss: 0.5747\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5589 - val_loss: 0.5741\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5790 - val_loss: 0.5734\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5653 - val_loss: 0.5728\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5701 - val_loss: 0.5721\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.5802 - val_loss: 0.5716\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5728 - val_loss: 0.5710\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 620us/step - loss: 0.5615 - val_loss: 0.5704\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5630 - val_loss: 0.5698\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5570 - val_loss: 0.5692\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5429 - val_loss: 0.5687\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5698 - val_loss: 0.5681\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5860 - val_loss: 0.5676\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.5528 - val_loss: 0.5670\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.5768 - val_loss: 0.5665\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5564 - val_loss: 0.5660\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.6026 - val_loss: 0.5655\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5720 - val_loss: 0.5650\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5738 - val_loss: 0.5645\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.5460 - val_loss: 0.5641\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5679 - val_loss: 0.5636\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5675 - val_loss: 0.5632\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5813 - val_loss: 0.5628\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5735 - val_loss: 0.5623\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5507 - val_loss: 0.5618\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5680 - val_loss: 0.5614\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5830 - val_loss: 0.5609\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.5605 - val_loss: 0.5605\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5716 - val_loss: 0.5601\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5654 - val_loss: 0.5597\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5510 - val_loss: 0.5593\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5652 - val_loss: 0.5590\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.5621 - val_loss: 0.5586\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.5410 - val_loss: 0.5582\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5634 - val_loss: 0.5578\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.5384 - val_loss: 0.5575\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.5338 - val_loss: 0.5572\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 479us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 831us/step - loss: 7.1033 - val_loss: 4.9969\n",
      "Epoch 2/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 4.6165 - val_loss: 3.7455\n",
      "Epoch 3/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 3.5625 - val_loss: 2.8790\n",
      "Epoch 4/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 2.8240 - val_loss: 2.2710\n",
      "Epoch 5/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - loss: 2.1677 - val_loss: 1.8400\n",
      "Epoch 6/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 1.7997 - val_loss: 1.5309\n",
      "Epoch 7/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 1.4453 - val_loss: 1.3077\n",
      "Epoch 8/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 1.2489 - val_loss: 1.1453\n",
      "Epoch 9/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 1.0656 - val_loss: 1.0263\n",
      "Epoch 10/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 1.0085 - val_loss: 0.9386\n",
      "Epoch 11/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.9466 - val_loss: 0.8738\n",
      "Epoch 12/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.8451 - val_loss: 0.8254\n",
      "Epoch 13/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.7884 - val_loss: 0.7891\n",
      "Epoch 14/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.7783 - val_loss: 0.7616\n",
      "Epoch 15/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.7645 - val_loss: 0.7407\n",
      "Epoch 16/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.6954 - val_loss: 0.7246\n",
      "Epoch 17/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.7429 - val_loss: 0.7120\n",
      "Epoch 18/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.6975 - val_loss: 0.7020\n",
      "Epoch 19/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.6796 - val_loss: 0.6939\n",
      "Epoch 20/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.6757 - val_loss: 0.6873\n",
      "Epoch 21/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6559 - val_loss: 0.6818\n",
      "Epoch 22/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.6802 - val_loss: 0.6772\n",
      "Epoch 23/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.6660 - val_loss: 0.6731\n",
      "Epoch 24/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.6350 - val_loss: 0.6695\n",
      "Epoch 25/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6892 - val_loss: 0.6663\n",
      "Epoch 26/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.6458 - val_loss: 0.6633\n",
      "Epoch 27/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6630 - val_loss: 0.6606\n",
      "Epoch 28/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6577 - val_loss: 0.6580\n",
      "Epoch 29/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.6764 - val_loss: 0.6556\n",
      "Epoch 30/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.6478 - val_loss: 0.6532\n",
      "Epoch 31/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.6504 - val_loss: 0.6510\n",
      "Epoch 32/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.6263 - val_loss: 0.6488\n",
      "Epoch 33/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - loss: 0.6493 - val_loss: 0.6467\n",
      "Epoch 34/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.6542 - val_loss: 0.6447\n",
      "Epoch 35/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.6034 - val_loss: 0.6426\n",
      "Epoch 36/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.6636 - val_loss: 0.6407\n",
      "Epoch 37/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.6551 - val_loss: 0.6389\n",
      "Epoch 38/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6516 - val_loss: 0.6370\n",
      "Epoch 39/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 0.6338 - val_loss: 0.6352\n",
      "Epoch 40/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.6303 - val_loss: 0.6334\n",
      "Epoch 41/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 0.6345 - val_loss: 0.6317\n",
      "Epoch 42/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 0.6336 - val_loss: 0.6299\n",
      "Epoch 43/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.6291 - val_loss: 0.6282\n",
      "Epoch 44/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.6336 - val_loss: 0.6266\n",
      "Epoch 45/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.6172 - val_loss: 0.6250\n",
      "Epoch 46/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.6280 - val_loss: 0.6235\n",
      "Epoch 47/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.6538 - val_loss: 0.6219\n",
      "Epoch 48/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 614us/step - loss: 0.6125 - val_loss: 0.6204\n",
      "Epoch 49/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.6015 - val_loss: 0.6189\n",
      "Epoch 50/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.6289 - val_loss: 0.6175\n",
      "Epoch 51/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6057 - val_loss: 0.6160\n",
      "Epoch 52/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step - loss: 0.5760 - val_loss: 0.6146\n",
      "Epoch 53/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.5917 - val_loss: 0.6133\n",
      "Epoch 54/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5811 - val_loss: 0.6119\n",
      "Epoch 55/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.6126 - val_loss: 0.6106\n",
      "Epoch 56/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.6087 - val_loss: 0.6093\n",
      "Epoch 57/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.6011 - val_loss: 0.6080\n",
      "Epoch 58/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.6311 - val_loss: 0.6068\n",
      "Epoch 59/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6230 - val_loss: 0.6056\n",
      "Epoch 60/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5977 - val_loss: 0.6044\n",
      "Epoch 61/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.5907 - val_loss: 0.6032\n",
      "Epoch 62/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5993 - val_loss: 0.6021\n",
      "Epoch 63/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5707 - val_loss: 0.6010\n",
      "Epoch 64/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.5967 - val_loss: 0.5998\n",
      "Epoch 65/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step - loss: 0.5723 - val_loss: 0.5988\n",
      "Epoch 66/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.5941 - val_loss: 0.5977\n",
      "Epoch 67/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 618us/step - loss: 0.5638 - val_loss: 0.5967\n",
      "Epoch 68/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5901 - val_loss: 0.5957\n",
      "Epoch 69/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5949 - val_loss: 0.5947\n",
      "Epoch 70/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.5923 - val_loss: 0.5937\n",
      "Epoch 71/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.5713 - val_loss: 0.5927\n",
      "Epoch 72/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5836 - val_loss: 0.5917\n",
      "Epoch 73/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.5723 - val_loss: 0.5907\n",
      "Epoch 74/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.5900 - val_loss: 0.5899\n",
      "Epoch 75/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5582 - val_loss: 0.5890\n",
      "Epoch 76/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5869 - val_loss: 0.5881\n",
      "Epoch 77/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.6038 - val_loss: 0.5873\n",
      "Epoch 78/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5809 - val_loss: 0.5864\n",
      "Epoch 79/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 611us/step - loss: 0.5750 - val_loss: 0.5856\n",
      "Epoch 80/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5738 - val_loss: 0.5848\n",
      "Epoch 81/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.5886 - val_loss: 0.5840\n",
      "Epoch 82/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 637us/step - loss: 0.5670 - val_loss: 0.5833\n",
      "Epoch 83/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 608us/step - loss: 0.5610 - val_loss: 0.5825\n",
      "Epoch 84/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 610us/step - loss: 0.5559 - val_loss: 0.5817\n",
      "Epoch 85/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5774 - val_loss: 0.5810\n",
      "Epoch 86/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5624 - val_loss: 0.5802\n",
      "Epoch 87/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5441 - val_loss: 0.5794\n",
      "Epoch 88/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5760 - val_loss: 0.5788\n",
      "Epoch 89/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.5592 - val_loss: 0.5783\n",
      "Epoch 90/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5779 - val_loss: 0.5774\n",
      "Epoch 91/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.5671 - val_loss: 0.5767\n",
      "Epoch 92/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 616us/step - loss: 0.5911 - val_loss: 0.5760\n",
      "Epoch 93/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 606us/step - loss: 0.5664 - val_loss: 0.5755\n",
      "Epoch 94/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.5712 - val_loss: 0.5750\n",
      "Epoch 95/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.5485 - val_loss: 0.5743\n",
      "Epoch 96/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.5587 - val_loss: 0.5737\n",
      "Epoch 97/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.5683 - val_loss: 0.5732\n",
      "Epoch 98/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.5842 - val_loss: 0.5726\n",
      "Epoch 99/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.5556 - val_loss: 0.5720\n",
      "Epoch 100/100\n",
      "\u001B[1m242/242\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 621us/step - loss: 0.5663 - val_loss: 0.5715\n",
      "\u001B[1m121/121\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 442us/step\n",
      "Epoch 1/100\n",
      "\u001B[1m  1/363\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m45s\u001B[0m 125ms/step - loss: 5.4383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grzegorz\\Desktop\\um\\neural_networks\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [ 7.78216742e-01  5.86569196e-01  7.36566012e-01  7.05440766e-01\n",
      "  5.92653998e-01             nan -3.51905894e+42  6.92226643e-01\n",
      "  7.41756972e-01  5.82444643e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 801us/step - loss: 1.2221 - val_loss: 0.5722\n",
      "Epoch 2/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.5092 - val_loss: 0.4597\n",
      "Epoch 3/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.4286 - val_loss: 0.4384\n",
      "Epoch 4/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.4192 - val_loss: 0.4314\n",
      "Epoch 5/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.4041 - val_loss: 0.4292\n",
      "Epoch 6/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3802 - val_loss: 0.4081\n",
      "Epoch 7/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.3943 - val_loss: 0.4050\n",
      "Epoch 8/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.3667 - val_loss: 0.3913\n",
      "Epoch 9/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.3772 - val_loss: 0.3831\n",
      "Epoch 10/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.3853 - val_loss: 0.3765\n",
      "Epoch 11/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.3617 - val_loss: 0.3722\n",
      "Epoch 12/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.3767 - val_loss: 0.3645\n",
      "Epoch 13/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.3619 - val_loss: 0.3579\n",
      "Epoch 14/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.3468 - val_loss: 0.4298\n",
      "Epoch 15/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.3300 - val_loss: 0.3583\n",
      "Epoch 16/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.3288 - val_loss: 0.3425\n",
      "Epoch 17/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.3418 - val_loss: 0.3450\n",
      "Epoch 18/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.3224 - val_loss: 0.3639\n",
      "Epoch 19/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.3640 - val_loss: 0.3446\n",
      "Epoch 20/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.3179 - val_loss: 0.3482\n",
      "Epoch 21/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.3239 - val_loss: 0.3363\n",
      "Epoch 22/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 602us/step - loss: 0.3281 - val_loss: 0.3376\n",
      "Epoch 23/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.3218 - val_loss: 0.3255\n",
      "Epoch 24/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.3054 - val_loss: 0.3255\n",
      "Epoch 25/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.3115 - val_loss: 0.3318\n",
      "Epoch 26/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.3047 - val_loss: 0.3288\n",
      "Epoch 27/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.3133 - val_loss: 0.3191\n",
      "Epoch 28/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.3115 - val_loss: 0.3239\n",
      "Epoch 29/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.3064 - val_loss: 0.3354\n",
      "Epoch 30/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 0.3068 - val_loss: 0.3228\n",
      "Epoch 31/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.3120 - val_loss: 0.3266\n",
      "Epoch 32/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.3054 - val_loss: 0.3225\n",
      "Epoch 33/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.3115 - val_loss: 0.3162\n",
      "Epoch 34/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 615us/step - loss: 0.2995 - val_loss: 0.3187\n",
      "Epoch 35/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.2915 - val_loss: 0.3201\n",
      "Epoch 36/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 582us/step - loss: 0.2785 - val_loss: 0.3180\n",
      "Epoch 37/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.2895 - val_loss: 0.3110\n",
      "Epoch 38/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.2964 - val_loss: 0.3249\n",
      "Epoch 39/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.2874 - val_loss: 0.3062\n",
      "Epoch 40/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 591us/step - loss: 0.2879 - val_loss: 0.3210\n",
      "Epoch 41/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.2918 - val_loss: 0.3171\n",
      "Epoch 42/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.2791 - val_loss: 0.3095\n",
      "Epoch 43/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.2809 - val_loss: 0.3068\n",
      "Epoch 44/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.2772 - val_loss: 0.3091\n",
      "Epoch 45/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - loss: 0.2783 - val_loss: 0.3093\n",
      "Epoch 46/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.2760 - val_loss: 0.3125\n",
      "Epoch 47/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.2792 - val_loss: 0.3013\n",
      "Epoch 48/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.2855 - val_loss: 0.3020\n",
      "Epoch 49/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.2750 - val_loss: 0.3104\n",
      "Epoch 50/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.2788 - val_loss: 0.3157\n",
      "Epoch 51/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 601us/step - loss: 0.2784 - val_loss: 0.3058\n",
      "Epoch 52/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.2820 - val_loss: 0.3011\n",
      "Epoch 53/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 627us/step - loss: 0.2756 - val_loss: 0.3126\n",
      "Epoch 54/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.2640 - val_loss: 0.3064\n",
      "Epoch 55/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 607us/step - loss: 0.2848 - val_loss: 0.2964\n",
      "Epoch 56/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.2855 - val_loss: 0.2948\n",
      "Epoch 57/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 604us/step - loss: 0.2717 - val_loss: 0.3068\n",
      "Epoch 58/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 586us/step - loss: 0.2897 - val_loss: 0.3061\n",
      "Epoch 59/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2762 - val_loss: 0.3003\n",
      "Epoch 60/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2812 - val_loss: 0.3080\n",
      "Epoch 61/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.2836 - val_loss: 0.3292\n",
      "Epoch 62/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 598us/step - loss: 0.2588 - val_loss: 0.3020\n",
      "Epoch 63/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.2682 - val_loss: 0.2990\n",
      "Epoch 64/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.2763 - val_loss: 0.3018\n",
      "Epoch 65/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.2754 - val_loss: 0.3399\n",
      "Epoch 66/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.2713 - val_loss: 0.3025\n",
      "Epoch 67/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.2809 - val_loss: 0.3062\n",
      "Epoch 68/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.2831 - val_loss: 0.2991\n",
      "Epoch 69/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 593us/step - loss: 0.2654 - val_loss: 0.3106\n",
      "Epoch 70/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.2630 - val_loss: 0.2947\n",
      "Epoch 71/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.2692 - val_loss: 0.3186\n",
      "Epoch 72/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 589us/step - loss: 0.2672 - val_loss: 0.3167\n",
      "Epoch 73/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.2659 - val_loss: 0.2986\n",
      "Epoch 74/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - loss: 0.2744 - val_loss: 0.2978\n",
      "Epoch 75/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.2757 - val_loss: 0.2963\n",
      "Epoch 76/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2641 - val_loss: 0.2944\n",
      "Epoch 77/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.2640 - val_loss: 0.3109\n",
      "Epoch 78/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 596us/step - loss: 0.2815 - val_loss: 0.2888\n",
      "Epoch 79/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2758 - val_loss: 0.2930\n",
      "Epoch 80/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2602 - val_loss: 0.3182\n",
      "Epoch 81/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 599us/step - loss: 0.2798 - val_loss: 0.2911\n",
      "Epoch 82/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 600us/step - loss: 0.2600 - val_loss: 0.2958\n",
      "Epoch 83/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.2582 - val_loss: 0.2904\n",
      "Epoch 84/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 590us/step - loss: 0.2579 - val_loss: 0.2905\n",
      "Epoch 85/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - loss: 0.2644 - val_loss: 0.2968\n",
      "Epoch 86/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.2542 - val_loss: 0.3167\n",
      "Epoch 87/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 588us/step - loss: 0.2692 - val_loss: 0.3105\n",
      "Epoch 88/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2805 - val_loss: 0.3022\n",
      "Epoch 89/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.2561 - val_loss: 0.2954\n",
      "Epoch 90/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 597us/step - loss: 0.2576 - val_loss: 0.2897\n",
      "Epoch 91/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 613us/step - loss: 0.2672 - val_loss: 0.2926\n",
      "Epoch 92/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 585us/step - loss: 0.2482 - val_loss: 0.2937\n",
      "Epoch 93/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.2445 - val_loss: 0.2886\n",
      "Epoch 94/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step - loss: 0.2546 - val_loss: 0.2878\n",
      "Epoch 95/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 605us/step - loss: 0.2589 - val_loss: 0.2879\n",
      "Epoch 96/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 587us/step - loss: 0.2546 - val_loss: 0.2969\n",
      "Epoch 97/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 0.2616 - val_loss: 0.2927\n",
      "Epoch 98/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 594us/step - loss: 0.2509 - val_loss: 0.3012\n",
      "Epoch 99/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 578us/step - loss: 0.2505 - val_loss: 0.2855\n",
      "Epoch 100/100\n",
      "\u001B[1m363/363\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step - loss: 0.2546 - val_loss: 0.2870\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3,\n                   estimator=KerasRegressor(input_shape=(8,), learning_rate=0.003, model=<function build_model at 0x0000021C8EEF0B80>, n_hidden=1, n_neurons=30),\n                   param_distributions={'learning_rate': [0.02649399056877689,\n                                                          0.007168487740858249,\n                                                          0.0003029571906483829,\n                                                          0.0032450056481498797,\n                                                          0.002316242867200746,\n                                                          0.0008318287461111042,\n                                                          0.001452402258287918,\n                                                          0.00...\n                                                          0.0020128373565954775,\n                                                          0.0037753471087948356,\n                                                          0.0003413560451613117,\n                                                          0.0012524609401976829,\n                                                          0.004486838978240833,\n                                                          0.0020723493799688656,\n                                                          0.012313496441782201,\n                                                          0.0016327560956401043,\n                                                          0.005455640287336193,\n                                                          0.008468217748216754,\n                                                          0.0013252948130273116, ...],\n                                        'n_hidden': [0, 1, 2, 3],\n                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                      10, 11, 12, 13, 14, 15,\n                                                      16, 17, 18, 19, 20, 21,\n                                                      22, 23, 24, 25, 26, 27,\n                                                      28, 29, 30, ...]})",
      "text/html": "<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=KerasRegressor(input_shape=(8,), learning_rate=0.003, model=&lt;function build_model at 0x0000021C8EEF0B80&gt;, n_hidden=1, n_neurons=30),\n                   param_distributions={&#x27;learning_rate&#x27;: [0.02649399056877689,\n                                                          0.007168487740858249,\n                                                          0.0003029571906483829,\n                                                          0.0032450056481498797,\n                                                          0.002316242867200746,\n                                                          0.0008318287461111042,\n                                                          0.001452402258287918,\n                                                          0.00...\n                                                          0.0020128373565954775,\n                                                          0.0037753471087948356,\n                                                          0.0003413560451613117,\n                                                          0.0012524609401976829,\n                                                          0.004486838978240833,\n                                                          0.0020723493799688656,\n                                                          0.012313496441782201,\n                                                          0.0016327560956401043,\n                                                          0.005455640287336193,\n                                                          0.008468217748216754,\n                                                          0.0013252948130273116, ...],\n                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                      10, 11, 12, 13, 14, 15,\n                                                      16, 17, 18, 19, 20, 21,\n                                                      22, 23, 24, 25, 26, 27,\n                                                      28, 29, 30, ...]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=KerasRegressor(input_shape=(8,), learning_rate=0.003, model=&lt;function build_model at 0x0000021C8EEF0B80&gt;, n_hidden=1, n_neurons=30),\n                   param_distributions={&#x27;learning_rate&#x27;: [0.02649399056877689,\n                                                          0.007168487740858249,\n                                                          0.0003029571906483829,\n                                                          0.0032450056481498797,\n                                                          0.002316242867200746,\n                                                          0.0008318287461111042,\n                                                          0.001452402258287918,\n                                                          0.00...\n                                                          0.0020128373565954775,\n                                                          0.0037753471087948356,\n                                                          0.0003413560451613117,\n                                                          0.0012524609401976829,\n                                                          0.004486838978240833,\n                                                          0.0020723493799688656,\n                                                          0.012313496441782201,\n                                                          0.0016327560956401043,\n                                                          0.005455640287336193,\n                                                          0.008468217748216754,\n                                                          0.0013252948130273116, ...],\n                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                      10, 11, 12, 13, 14, 15,\n                                                      16, 17, 18, 19, 20, 21,\n                                                      22, 23, 24, 25, 26, 27,\n                                                      28, 29, 30, ...]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n\tmodel=&lt;function build_model at 0x0000021C8EEF0B80&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tn_hidden=2\n\tn_neurons=99\n\tlearning_rate=0.010095727083442635\n\tinput_shape=(8,)\n)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">KerasRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>KerasRegressor(\n\tmodel=&lt;function build_model at 0x0000021C8EEF0B80&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=1\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n\tn_hidden=2\n\tn_neurons=99\n\tlearning_rate=0.010095727083442635\n\tinput_shape=(8,)\n)</pre></div> </div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:16:24.901643900Z",
     "start_time": "2024-10-01T18:07:23.563257400Z"
    }
   },
   "id": "93d81ff39ce87b22",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_neurons': 99, 'n_hidden': 2, 'learning_rate': 0.010095727083442635}"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:16:24.906008500Z",
     "start_time": "2024-10-01T18:16:24.900643400Z"
    }
   },
   "id": "f8bf4df29246de83",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.7782167415888589"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:16:24.937345800Z",
     "start_time": "2024-10-01T18:16:24.904012100Z"
    }
   },
   "id": "b0da1119f64ea803",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:16:24.948345300Z",
     "start_time": "2024-10-01T18:16:24.924014500Z"
    }
   },
   "id": "983359ab151b8314",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save(\"my_best_model.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T18:16:24.939345500Z",
     "start_time": "2024-10-01T18:16:24.909007900Z"
    }
   },
   "id": "ab7112d6cc0d400a",
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
